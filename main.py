import pathlib
import argparse
import yaml
from dotenv import load_dotenv
from src.utils.utils import init_logger
from src.utils.utils import process_dataframe
from src.utils.utils import generate_acronym_expansion_json
from src.acronyms.acronym_expander import HermesAcronymExpander
from src.acronyms.acronym_detector import HermesAcronymDetector


def load_config(config_path):
    """
    Load configuration from YAML.
    """
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

if __name__ == "__main__":
    
    config_path = pathlib.Path("config/settings.yaml")
    config = load_config(config_path)
    
    # Initialize logger
    logger = init_logger(config['logger'])
    logger.info("Cargando la configuración desde YAML...")
    
    logger.info("Cargando las variables de entorno desde el archivo .env...")
    path_env = pathlib.Path(
            "/export/usuarios_ml4ds/cggamella/RAG_tool/.env")
    load_dotenv(path_env)
    
    parser = argparse.ArgumentParser(description="Acronym Detection and Expansion Tool")
    parser.add_argument("--llm_type", type=str, default="llama",
                        help="Type of large language model to use") # llama or openai
    parser.add_argument("--data_path", type=str,
                        help="Path to data file",
                        default='/export/usuarios_ml4ds/cggamella/RAG_tool/files/acronyms_paper.xlsx')
    parser.add_argument("--action", type=str, choices=["detect", "expand", "both"], default="both",
                        help="Action to perform: detect acronyms, expand acronyms, or both")
    parser.add_argument("--do_train", action='store_true',
                        help="Indicate if the models should be trained.")
    parser.add_argument("--context_window", type=int, default=3000,  
                        help="Size of the context window for the chunker")
    parser.add_argument("--max_windows", type=int, default=100,
                        help="Maximum number of windows the chunker can generate")
    parser.add_argument("--window_overlap", type=float, default=0.1,
                        help="Percentage of overlap between windows generated by the chunker")

    args = parser.parse_args()
    
    # Initialize the acronym detector and expander    
    expander = None
    detector = None
    
    # Decide whether to train based on configuration file and arguments
    do_train = getattr(args, 'do_train', False) or config.get('train_all_modules', False)
    # Get the column name from the configuration
    column_name = config.get('data_column_name', 'text')
    
    detector = None
    if args.action in ["detect", "both"]:
        ########################################
        # Initialize and use HermesAcronymDetector
        ########################################
        # Path to trained model json file with dspy
        trained_promt_detector = pathlib.Path("data/optimized/HermesAcronymDetector-saved.json")
        # Verify if the model should be trained
        should_train = do_train or "HermesAcronymDetector" in (config.get('modules_to_train') or [])

        if should_train:
            # Train the model
            logger.info("Entrenando y usando HermesAcronymDetector...")
            detector = HermesAcronymDetector(
                model_type=args.llm_type,
                do_train=True,
                data_path=args.data_path,
                trained_promt=trained_promt_detector,
                logger=logger
            )
            '''
            # Configure the module to use the Retry transformation with a maximum of 2 backtracks
            detector.module = assert_transform_module(
                detector.module.map_named_predictors(dspy.Retry),
                functools.partial(backtrack_handler, max_backtracks=5) 
            )
            '''
            # After training, verify if the model was saved correctly
            if not trained_promt_detector.exists():
                logger.error(f"El modelo entrenado no se guardó correctamente en {trained_promt_detector}.")
                raise FileNotFoundError(f"El modelo entrenado no se encuentra en {trained_promt_detector}.")
        else:
            # Use the pre-trained model
            if trained_promt_detector.exists():
                logger.info(f"Cargando AcronymDetectorModule preentrenado desde {trained_promt_detector}...")
                detector = HermesAcronymDetector(
                    model_type=args.llm_type,
                    do_train=False,
                    data_path=args.data_path,
                    trained_promt=trained_promt_detector,
                    logger=logger
                )
                '''
                detector.module = assert_transform_module(
                    detector.module.map_named_predictors(dspy.Retry),
                    functools.partial(backtrack_handler, max_backtracks=2) 
                )
                '''
            else:
                # If the model don´t have trained_promt, raise an error
                logger.error(f"No se encontró el modelo entrenado en {trained_promt_detector}. Considera entrenarlo primero.")
                raise FileNotFoundError(f"El modelo entrenado no existe en {trained_promt_detector}. Entrena el modelo antes de usarlo.")
             
    expander = None
    if args.action in ["expand", "both"]:
        ########################################
        # Initialize and use HermesAcronymExpander
        ########################################
        # Verify if the model should be trained
        should_train = do_train or "HermesAcronymExpander" in (config.get('modules_to_train') or [])
        
        # Path to trained model json file with dspy
        trained_promt_expander = pathlib.Path("data/optimized/HermesAcronymExpander-saved.json")

        if should_train:
            # Train the model
            logger.info("Entrenando y usando HermesAcronymExpander...")
            expander = HermesAcronymExpander(
                model_type=args.llm_type,
                do_train=True,
                data_path=args.data_path,
                trained_promt=trained_promt_expander,
                logger=logger
            )
            '''
            # Configure the module to use the Retry transformation with a maximum of 2 backtracks
            expander.module = assert_transform_module(
                expander.module.map_named_predictors(dspy.Retry),
                functools.partial(backtrack_handler, max_backtracks=2) 
            )
            '''
            # After training, verify if the model was saved correctly
            if not trained_promt_expander.exists():
                logger.error(f"El modelo entrenado no se guardó correctamente en {trained_promt_expander}.")
                raise FileNotFoundError(f"El modelo entrenado no se encuentra en {trained_promt_expander}.")
        else:
            # Use the pre-trained model
            if trained_promt_expander.exists():
                logger.info(f"Cargando AcronymExpanderModule preentrenado desde {trained_promt_expander}...")
                expander = HermesAcronymExpander(
                    model_type=args.llm_type,
                    do_train=False,
                    data_path=args.data_path,
                    trained_promt=trained_promt_expander,
                    logger=logger
                )
                '''
                # Configure the module to use the Retry transformation with a maximum of 2 backtracks
                expander.module = assert_transform_module(
                    expander.module.map_named_predictors(dspy.Retry),
                    functools.partial(backtrack_handler, max_backtracks=2) 
                )
                '''
            else:
                # If the model don´t have trained_promt, raise an error
                logger.error(f"No se encontró el modelo entrenado en {trained_promt_expander}. Considera entrenarlo primero.")
                raise FileNotFoundError(f"El modelo entrenado no existe en {trained_promt_expander}. Entrena el modelo antes de usarlo.")
        
    # Process the DataFrame
    try:
        df_out = process_dataframe(
            path=args.data_path,
            config=config,
            action=args.action,
            acronym_detector=detector.module if detector else None,
            acronym_expander=expander.module if expander else None,
            context_window=args.context_window,
            max_windows=args.max_windows,
            window_overlap=args.window_overlap,
            logger=logger
        )
    except Exception as e:
        logger.error(f"Error occured processing dataframe: {str(e)}")
        raise e
        
    # Save df in a new Excel file with the same name as the input file plus '_out'
    if args.action == "detect":
        suffix = "_detect"
    elif args.action == "expand":
        suffix = "_expand"
    elif args.action == "both":
        suffix = "_both"
    else:
        suffix = "_out"  

    # Save the processed DataFrame to an Excel file
    path = pathlib.Path(args.data_path)
    path_out = path.with_stem(path.stem + suffix).with_suffix('.xlsx')
    df_out.to_excel(path_out, index=False)
    # Report the path of the saved file
    logger.info(f"DataFrame procesado con la acción '{args.action}' y guardado en {path_out}")
    
    # Generate JSON with detected and expanded acronyms only with both args
    if args.action == "both":
        path_sal = '/export/usuarios_ml4ds/cggamella/RAG_tool/src/topicmodeling/data/acronyms/'
        generate_acronym_expansion_json(path_out, path_sal)
        logger.info(f"JSON with detected and expanded acronyms saved on {path_sal}")
    
    