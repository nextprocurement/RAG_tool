import argparse
import pathlib
import time
import yaml
import json
from src.equivalences.equivalences_generator import HermesEquivalencesGenerator
from src.utils.tm_utils import train_model
from src.utils.utils import (init_logger, process_dataframe, generate_acronym_expansion_json)

def load_config(config_path):
    """
    Load configuration from YAML.
    """
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

def main():
    ###############################################
    #               GENERAL ARGUMENTS             #  
    ###############################################
    parser = argparse.ArgumentParser(description="HERMES pipeline")
    parser.add_argument(
        "--llm_type",
        type=str,
        default="llama",
        help="Type of large language model to use (llama, openai, mistral...)") 
    parser.add_argument(
        "--data_path",
        type=str,
        help="Path to data file",
        default='/export/data_ml4ds/NextProcurement/temporal/zaragoza_objectives_extracted_final_with_lemmas.parquet')
    parser.add_argument(
        "--save_path",
        type=str,
        help="Path to save the output files",
        default="/export/data_ml4ds/NextProcurement/temporal/zaragoza_models")
    parser.add_argument(
        "--mode",
        type=str,
        default="optimized",
        help="Mode of operation (optimized or non-optimized)")

    ###############################################
    # ACRONYM DETECTION AND EXPANSION ARGUMENTS   #
    ###############################################
    parser.add_argument(
        "--do_train",
        action='store_true',
        help="Indicate if the models should be trained.")
    parser.add_argument(
        "--train_data_path",
        type=str,
        default=None,
        help="Path to training DSPy modules for the acronym detector and expander"
    )
    parser.add_argument(
        "--context_window",
        type=int,
        default=3000,
        help="Size of the context window for the chunker")
    parser.add_argument(
        "--max_windows", 
        type=int,
        default=100,
        help="Maximum number of windows the chunker can generate")
    parser.add_argument(
        "--window_overlap",
        type=float,
        default=0.1,
        help="Percentage of overlap between windows generated by the chunker")
    
    ###############################################
    #           PREPROCESSING ARGUMENTS           #
    ###############################################
    parser.add_argument(
        "--preproc_source",
        type=str,
        default="cpv45",
        help="Source of the data in the preproc file (config.json)")

    ###############################################
    #         EQUIVALENCE DETECTION ARGUMENTS     #
    ###############################################
    parser.add_argument(
        "--source_eq",
        action='store_true',
        default="tm",
        help="Source of the equivalences (vocabulary or tm)")
    parser.add_argument(
        "--times_equiv",
        action='store_true',
        default=3, # For final models fix to 3
        help="Number of times to run the equivalence detection"
    )
        
    ###############################################
    #               TRAINING ARGUMENTS            #
    ###############################################
    parser.add_argument(
        "--num_topics",
        help="Number of topics",
        type=str, default="5,6,7,8,9,10,15,20,30", required=False)
    parser.add_argument(
        "--num_iters",
        help="Number of iterations",
        type=int, default=1000, required=False)
    parser.add_argument(
        "--model_type",
        help="type of the model, MalletLda, Ctm, BERTopic, all",
        type=str, default='MalletLda', required=False)
    parser.add_argument(
        "--sample",
        help="how many documents to run",
        type=int, 
        required=False,
        default=100
    )
    parser.add_argument(
        "--do_second_level",
        help="Whether to generate second-level topics.",
        type=bool, 
        default=True
    )
    parser.add_argument(
        "--further_proc",
        help="Whether to further process the data.",
        type=bool, 
        default=True
    )
    
    # ***********************************************************************
    # 0. Setup
    # ***********************************************************************
    config_path = pathlib.Path("config/settings.yaml")
    config = load_config(config_path)
    logger = init_logger(config['logger'])
    args = parser.parse_args()

    
    logger.info(f"-- -- Running HERMES pipeline in optimized mode...")
                
    #***********************************************************************
    # 3. Equivalence Detection
    #***********************************************************************
    logger.info("#"*80)
    logger.info(f"### 3. Equivalence Detection ###")
    logger.info("#"*80)
    
    load_data_path = pathlib.Path(args.data_path)
    path_save = pathlib.Path(args.save_path) / '3.equivalence_detection'
    if not path_save.exists():
        path_save.mkdir(parents=True)
    
    path_save_eqs = path_save / 'equivalences_lst'
    if path_save_eqs.exists():
        logger.info(f"--- Equivalences output already exists at {path_save_eqs.as_posix()}. Continue with training...")
    else:
        path_save_eqs.mkdir(parents=True, exist_ok=True)
        

        file_save = pathlib.Path(args.data_path).stem + '.json'
        path_save_eqs_file = path_save_eqs / file_save

        eq_generator = HermesEquivalencesGenerator(
            model_type = config['llm']['model_type'],
            use_optimized = True,
            do_train = True,
            lang=config['preproc']['lang']
        )

        if args.source_eq == "vocabulary":
            
            this_path_save_eqs = path_save_eqs_file.parent / f"{path_save_eqs_file.stem}_vocabulary.json"
            
            if this_path_save_eqs.exists():
                logger.info(f"-- -- Equivalences output already exists at {this_path_save_eqs.as_posix()}")
            else:
                logger.info(f"-- -- Equivalences output does not exist at {this_path_save_eqs.as_posix()}")
                logger.info(f"-- -- Running Equivalence Detection...")
                time_start = time.time()    
            
            # Train auxiliary topic model
            model_path = path_save / pathlib.Path(args.data_path).stem /'aux_topic_model_vocabulary'
            
            if model_path.exists():
                logger.info(f"-- -- Auxiliary topic model already exists at {model_path}. Using it...")
            else:
                model_path.mkdir(parents=True)
                logger.info(f"-- -- Training auxiliary topic model for vocabulary...")

                this_args = argparse.Namespace(
                    **{k: v for k, v in vars(args).items() 
                    if v is not None and k in ["further_proc", "sample", "num_iters"]})

                # Assign new values to the copied Namespace object
                this_args.model_path = model_path.as_posix()
                this_args.load_data_path = load_data_path.as_posix()
                this_args.num_topics = config['equiv']['num_topics_equiv']
                this_args.logger = logger
                                
                model = train_model(
                    model_path = model_path.as_posix(),
                    model_type = config['equiv']['model_name'],
                    num_topics = config['equiv']['num_topics_equiv'],
                    further_proc = config['equiv']['further_proc'],
                    logger = logger,
                    env = pathlib.Path(config['llm']['env']),
                    args = this_args,
                    stw_path = 'data/stops',
                    eq_path = path_save_eqs_file
                )
                topics = model.print_topics()
                print(f"-- -- Topics from auxiliary trained model: {topics}")
                for i, topic in enumerate(topics):
                    print("Topic #", i)
                    print(topics[topic])
            
            if args.source_eq == "vocabulary":
                path_to_source = (
                    model_path /
                    f"{config['equiv']['model_name']}_{config['equiv']['num_topics_equiv']}" /
                    "vocabulary.txt"
                )
            else:
                path_to_source = (
                    model_path /
                    f"{config['equiv']['model_name']}_{config['equiv']['num_topics_equiv']}"
                ) 
            
            try:
                logger.info(f"-- -- Generating equivalences from {args.source_eq}...") 

                json_data_old, json_data_new, stats = eq_generator.generate_equivalences(
                    source=args.source_eq,
                    path_to_source=path_to_source,
                    path_save=this_path_save_eqs,
                    model_type=config['equiv']['model_name'],
                    language=config['preproc']['lang'],
                    top_k=config['equiv']['top_k'],
                )
                
                # Paths to save the JSON files
                #path_save_old = path_save_eqs.with_name(f"{path_save_eqs.stem}_old{path_save_eqs.suffix}.json")
                #path_save_new = path_save_eqs.with_name(f"{path_save_eqs.stem}_new{path_save_eqs.suffix}.json")
                #path_save_stats = path_save_eqs.with_name(f"{path_save_eqs.stem}_stats.json")

                #with open(path_save_old, 'w', encoding='utf-8') as json_file:
                #    json.dump(json_data_old, json_file, indent=4, #ensure_ascii=False)
                #logger.info(f"-- -- Old equivalences saved to {path_save_old}")
                with open(path_save_new, 'w', encoding='utf-8') as json_file:
                    json.dump(json_data_new, json_file, indent=4, ensure_ascii=False)
                logger.info(f"-- -- New equivalences saved to {path_save_new}")
                
                # Save statistics of clustering in a JSON file
                with open(path_save_stats, 'w', encoding='utf-8') as json_file:
                    json.dump(stats, json_file, indent=4, ensure_ascii=False)
                logger.info(f"-- -- Paper equivalences statistics saved to {path_save_stats}")
                logger.info(f"-- -- Equivalences generation completed successfully.")

            except Exception as e:
                logger.error(f"Error during equivalence generation or saving: {e}")

            logger.info(f"-- -- Equivalences saved to {this_path_save_eqs}")
        
        elif args.source_eq == "tm":
            
            logger.info(f"-- -- Running equivalence detection for TM {args.times_equiv} times...")
        
            for t in range(args.times_equiv):
                
                #this_path_save_eqs = path_save_eqs.parent / f"{path_save_eqs.stem}_{t+1}.json"
                
                if not path_save_eqs.exists():
                    
                    logger.info(f"-- -- Running equivalence detection {t+1} out of {args.times_equiv}...")
            
                    # Train auxiliary topic model
                    model_path = path_save / pathlib.Path(args.data_path).stem /f'aux_topic_model_tm_{t+1}'
                    
                    if model_path.exists():
                        logger.info(f"-- -- Auxiliary topic model already exists at {model_path}. Using it...")
                    else:
                        model_path.mkdir(parents=True)
                        logger.info(f"-- -- Training auxiliary topic model for TM {t+1}...")

                        this_args = argparse.Namespace(
                            **{k: v for k, v in vars(args).items() 
                            if v is not None and k in ["further_proc", "sample", "num_iters"]})

                        # Assign new values to the copied Namespace object
                        this_args.model_path = model_path.as_posix()
                        this_args.load_data_path = load_data_path.as_posix()
                        this_args.num_topics = config['equiv']['num_topics_equiv']
                        this_args.logger = logger
                                        
                        model = train_model(
                            model_path = model_path.as_posix(),
                            model_type = config['equiv']['model_name'],
                            num_topics = config['equiv']['num_topics_equiv'],
                            further_proc = config['equiv']['further_proc'],
                            logger = logger,
                            env = pathlib.Path(config['llm']['env']),
                            args = this_args,
                            stw_path = 'data/stops',
                            eq_path = path_save_eqs
                        )
                        topics = model.print_topics()
                        print(f"-- -- Topics from auxiliary trained model: {topics}")
                        for i, topic in enumerate(topics):
                            print("Topic #", i)
                            print(topics[topic])
                    
                    path_to_source = model_path / f"{config['equiv']['model_name']}_{config['equiv']['num_topics_equiv']}" / "vocabulary.txt" if args.source_eq == "vocabulary" else model_path / f"{config['equiv']['model_name']}_{config['equiv']['num_topics_equiv']}"

                    try:
                        logger.info(f"-- -- Generating equivalences from {args.source_eq}...") 

                        json_data_old, json_data_new, stats = eq_generator.generate_equivalences(
                            source=args.source_eq,
                            path_to_source=path_to_source,
                            path_save=this_path_save_eqs,
                            model_type=config['equiv']['model_name'],
                            language=config['preproc']['lang'],
                            top_k=config['equiv']['top_k'],
                        )
                        
                        # Paths to save the JSON files
                        path_save_old = path_save_eqs / f"{path_save_eqs.stem}_old.json"
                        path_save_new = path_save_eqs / f"{path_save_eqs.stem}_new.json"         
                        path_save_stats = path_save_eqs.parent / f"{path_save_eqs.stem}_stats.json"
                        
                        with open(path_save_old, 'w', encoding='utf-8') as json_file:
                            json.dump(json_data_old, json_file, indent=4, ensure_ascii=False)
                        logger.info(f"-- -- Old equivalences saved to {path_save_old}")
                        with open(path_save_new, 'w', encoding='utf-8') as json_file:
                            json.dump(json_data_new, json_file, indent=4, ensure_ascii=False)
                        logger.info(f"-- -- New equivalences saved to {path_save_new}")
                        
                        # Save statistics of clustering in a JSON file
                        with open(path_save_stats, 'w', encoding='utf-8') as json_file:
                            json.dump(stats, json_file, indent=4, ensure_ascii=False)
                        logger.info(f"-- -- Paper equivalences statistics saved to {path_save_stats}")
                        logger.info(f"-- -- Equivalences generation completed successfully.")

                    except Exception as e:
                        logger.error(f"Error during equivalence generation or saving: {e}")
                
                else:
                    print(f"-- -- Equivalences output already exists at {path_save_eqs.as_posix()}")
                    continue

        else:
            logger.error(f"-- -- Source of equivalences not recognized. Please provide a valid source.")
            return
    
    #**********************************************************************
    # 4. Training
    #***********************************************************************
    logger.info("#"*80)
    logger.info(f"### 4. Training ###")
    logger.info("#"*80)
    
    path_save = pathlib.Path(args.save_path) / '4.training'
    if not path_save.exists():
        path_save.mkdir(parents=True)
        
    model_path = path_save / pathlib.Path(args.data_path).stem
    if not model_path.exists():
        model_path.mkdir(parents=True)
        logger.info(f"-- --Creating {model_path.as_posix()} ...")       

    try:
        num_topics_lst = args.num_topics.split(",")
        num_topics_lst = [int(num) for num in num_topics_lst]
    except Exception as e:
        logger.info(f"-- -- Error splitting num_topics: {str(e)}. Number of topics is not a list.")
        num_topics_lst = [int(args.num_topics)]
    
    for num_topics in num_topics_lst:
        this_args = argparse.Namespace(
            **{k: v for k, v in vars(args).items() 
            if v is not None and k in ["further_proc", "sample", "num_iters"]})

        # Assign new values to the copied Namespace object
        this_args.model_path = model_path.as_posix()
        this_args.load_data_path = load_data_path.as_posix()
        this_args.num_topics = num_topics#args.num_topics
        this_args.logger = logger
        
        if args.model_type == 'all':
            logger.info( "-- -- Training all models...")
            models = ['MalletLda', 'Ctm', 'BERTopic', 'TopicGPT']
        else:
            logger.info( f"-- -- Training model of type {args.model_type}...")
            models = [args.model_type]
        
        for model_type in models:
            
                if model_type == 'Ctm':
                    this_args.num_iters = 50
                    logger.info(f"-- -- Training model with {this_args.num_iters} iterations because it is a Ctm model...")
                else:
                    this_args.num_iters = args.num_iters
                    
                model = train_model(
                    model_path = model_path.as_posix(),
                    model_type = model_type,
                    num_topics = num_topics,
                    further_proc = args.further_proc,
                    logger = logger,
                    env = pathlib.Path(config['llm']['env']),
                    args = this_args,
                    stw_path = 'data/stops',
                    eq_path = path_save_eqs
                )
                topics = model.print_topics()
                print(f"-- -- Topics from auxiliary trained model: {topics}")
                for i, topic in enumerate(topics):
                    print("Topic #", i)
                    print(topics[topic])

if __name__ == "__main__":
    main()


