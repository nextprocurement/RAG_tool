{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96c4b52",
   "metadata": {},
   "source": [
    "# INTEGRACIÓN PARA CONSTRUCCIÓN DE UN GOLDEN DATASET CON API GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbee4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "\n",
    "#pip install --upgrade openai==1.1.1\n",
    "#pip install cohere tiktoken\n",
    "#!pip3 install python-dotenv\n",
    "\n",
    "#print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959172b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo = '/export/usuarios_ml4ds/cggamella/RAG_tool/dataset_pruebas.xlsx'\n",
    "# Utiliza la función to_excel para exportar el DataFrame a un archivo Excel\n",
    "df = pd.read_excel(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39e52cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronyms</th>\n",
       "      <th>expanded_acronyms</th>\n",
       "      <th>text</th>\n",
       "      <th>detected_acronyms</th>\n",
       "      <th>LLM_expanded_acronyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ONG</td>\n",
       "      <td>ONG</td>\n",
       "      <td>Las ONG son organizaciones no gubernamentales ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIA, FBI</td>\n",
       "      <td>CIA, FBI</td>\n",
       "      <td>La CIA y el FBI colaboran en investigaciones i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UE, OTAN</td>\n",
       "      <td>UE, OTAN</td>\n",
       "      <td>La unión europea y la OTAN tienen roles crucia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASA</td>\n",
       "      <td>NASA</td>\n",
       "      <td>La NASA es la agencia espacial estadounidense,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNICEF</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>UNICEF, trabajan por los derechos de los niños...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FAQ</td>\n",
       "      <td>FAQ</td>\n",
       "      <td>La sección de preguntas frecuentes FAQ proporc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CEO</td>\n",
       "      <td>CEO</td>\n",
       "      <td>El CEO de la compañía anunció planes de expans...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>CFO</td>\n",
       "      <td>CFO</td>\n",
       "      <td>El chief financial officer presentó el informe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CTO</td>\n",
       "      <td>CTO</td>\n",
       "      <td>El CTO lidera el equipo de desarrollo tecnológ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rrhh</td>\n",
       "      <td>rrhh</td>\n",
       "      <td>El departamento de recursos humanos está reclu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acronyms expanded_acronyms  \\\n",
       "0        ONG               ONG   \n",
       "1   CIA, FBI          CIA, FBI   \n",
       "2   UE, OTAN          UE, OTAN   \n",
       "3       NASA              NASA   \n",
       "4     UNICEF            UNICEF   \n",
       "..       ...               ...   \n",
       "63       FAQ               FAQ   \n",
       "64       CEO               CEO   \n",
       "65       CFO               CFO   \n",
       "66       CTO               CTO   \n",
       "67      rrhh              rrhh   \n",
       "\n",
       "                                                 text  detected_acronyms  \\\n",
       "0   Las ONG son organizaciones no gubernamentales ...                NaN   \n",
       "1   La CIA y el FBI colaboran en investigaciones i...                NaN   \n",
       "2   La unión europea y la OTAN tienen roles crucia...                NaN   \n",
       "3   La NASA es la agencia espacial estadounidense,...                NaN   \n",
       "4   UNICEF, trabajan por los derechos de los niños...                NaN   \n",
       "..                                                ...                ...   \n",
       "63  La sección de preguntas frecuentes FAQ proporc...                NaN   \n",
       "64  El CEO de la compañía anunció planes de expans...                NaN   \n",
       "65  El chief financial officer presentó el informe...                NaN   \n",
       "66  El CTO lidera el equipo de desarrollo tecnológ...                NaN   \n",
       "67  El departamento de recursos humanos está reclu...                NaN   \n",
       "\n",
       "    LLM_expanded_acronyms  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "..                    ...  \n",
       "63                    NaN  \n",
       "64                    NaN  \n",
       "65                    NaN  \n",
       "66                    NaN  \n",
       "67                    NaN  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3a291",
   "metadata": {},
   "source": [
    "## Integración OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e0045",
   "metadata": {},
   "source": [
    "Esta función sirve para generar las queries asociadas a los servicios, cat y subcat con el modelo de GPT-3.5 Turbo, además se crea una función auxiliar para crear la base de datos escribiendo en el campo necesario la información de la Categoría, Subcategoría, Servicio, Query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_queries_servicios(category_dict):\n",
    "    \n",
    "    data = [] \n",
    "\n",
    "    for categoria, subcategorias in category_dict.items():\n",
    "        for subcategoria, servicios in subcategorias.items():\n",
    "            for servicio in servicios:\n",
    "                try:\n",
    "                    completion = openai.chat.completions.create(\n",
    "                        model=\"gpt-3.5-turbo-0125\",\n",
    "                        messages=[\n",
    "                          {\"role\": \"system\", \"content\": \"You are a nice and helpful assistant.I need your imagination to create some queries that a human can send to find a service or professional. Language used must be Spanish.\"},\n",
    "                          {\"role\": \"user\", \"content\": f\"Generate 5 examples of queries that a user without specific knowledge could make describing his issue looking for services related to the service name: {servicio},which belongs to subcategory: {subcategoria}, which is part of the category {categoria}. Each query should be no longer than 8 words, not being enumerated neither with quotation marks, provide plain text\"}\n",
    "                        ],\n",
    "                        temperature = 0.7, #Es configurable entre 0 y 2, cuanto más alto sea, el modelo es más creativo\n",
    "                        max_tokens = 300 # Para limitar el número de tokens, aproximadamente 100 tokens son 75 palabras\n",
    "                    )\n",
    "                    # Acceder directamente al texto generado y dividirlo en líneas para obtener las queries\n",
    "                    queries = completion.choices[0].message.content.strip().split('\\n')\n",
    "                    \n",
    "                    return queries\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Se produjo un error al generar las queries para el servicio {servicio} en {subcategoria} de {categoria}: {e}\")\n",
    "                    # Continúa con el siguiente servicio en caso de error\n",
    "                    continue\n",
    "\n",
    "def generar_tabla_queries(category_dict):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Itera sobre el diccionario de categorías\n",
    "    for categoria, subcategorias in category_dict.items():\n",
    "        for subcategoria, servicios in subcategorias.items():\n",
    "            for servicio in servicios:\n",
    "                # Obtiene las queries para el servicio actual\n",
    "                queries = generar_queries_servicios({categoria: {subcategoria: [servicio]}})\n",
    "                # Añade cada query al listado de datos\n",
    "                for query in queries:\n",
    "                    data.append({\n",
    "                        \"Categoría\": categoria,\n",
    "                        \"Subcategoría\": subcategoria,\n",
    "                        \"Servicio\": servicio,\n",
    "                        \"Query\": query\n",
    "                    })\n",
    "\n",
    "    # Crea un DataFrame con los datos acumulados\n",
    "    df_queries = pd.DataFrame(data)\n",
    "\n",
    "    # Devuelve el DataFrame\n",
    "    return df_queries\n",
    "\n",
    "\n",
    "# Genera el DataFrame con las queries\n",
    "df_queries = generar_tabla_queries(category_dict)\n",
    "\n",
    "# Guarda el DataFrame en un archivo Excel\n",
    "df_queries.to_excel(\"queries_sinteticas_servicios.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3baee28",
   "metadata": {},
   "source": [
    "Ha tardado 1h 8 mins en generar 5205 queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e476c83",
   "metadata": {},
   "source": [
    "Leyendo el archivo de queries_sintéticas creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbdd = pd.read_excel(\"queries_sinteticas_servicios.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf32e53",
   "metadata": {},
   "source": [
    "## Integración para acronyms con DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb28744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/stanfordnlp/dspy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f89e441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pydantic\n",
    "#!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bdf366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b185dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para dar formato al output del terminal\n",
    "class Colors:\n",
    "    BLUE = '\\033[94m'\n",
    "    ENDC = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3cb8c766-17c5-47e7-abcc-d79cbb8c3828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/usuarios_ml4ds/lbartolome/NextProcurement/NP-Search-Tool/.env\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#   LLM   #\n",
    "###########\n",
    "path_env = pathlib.Path(\"/export/usuarios_ml4ds/lbartolome/NextProcurement/NP-Search-Tool/.env\")\n",
    "print(path_env)\n",
    "load_dotenv(path_env)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "#lm = dspy.HFClientTGI(model=\"meta-llama/Meta-Llama-3-8B \", port=8080, url=\"http://127.0.0.1\")\n",
    "lm = dspy.OpenAI(model=\"gpt-3.5-turbo\")# \"gpt-4o-2024-05-13\")\n",
    "\n",
    "dspy.settings.configure(lm=lm, temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43127119-cfc7-4e55-a35d-b1bf89a65eb4",
   "metadata": {},
   "source": [
    "### Just checking that DSPY with LLAMA works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d0793e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Llama-3-8B: Sunday\n"
     ]
    }
   ],
   "source": [
    "qa = dspy.ChainOfThought('question -> answer')\n",
    "\n",
    "# Run with Llama instead\n",
    "with dspy.context(lm=lm):\n",
    "    response = qa(question=\"What is the first day of the week?\")\n",
    "    print('Meta-Llama-3-8B:', response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e3d9b-15f0-409c-bee2-fd8bab2f8cd0",
   "metadata": {},
   "source": [
    "### Synthetic acronymn generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a194a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronyms</th>\n",
       "      <th>expanded_acronyms</th>\n",
       "      <th>text</th>\n",
       "      <th>detected_acronyms</th>\n",
       "      <th>LLM_expanded_acronyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ONG</td>\n",
       "      <td>ONG</td>\n",
       "      <td>Las ONG son organizaciones no gubernamentales ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIA, FBI</td>\n",
       "      <td>CIA, FBI</td>\n",
       "      <td>La CIA y el FBI colaboran en investigaciones i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acronyms expanded_acronyms  \\\n",
       "0       ONG               ONG   \n",
       "1  CIA, FBI          CIA, FBI   \n",
       "\n",
       "                                                text  detected_acronyms  \\\n",
       "0  Las ONG son organizaciones no gubernamentales ...                NaN   \n",
       "1  La CIA y el FBI colaboran en investigaciones i...                NaN   \n",
       "\n",
       "   LLM_expanded_acronyms  \n",
       "0                    NaN  \n",
       "1                    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar dataframe donde se guardará la información \n",
    "ruta_archivo = '/export/usuarios_ml4ds/cggamella/RAG_tool/dataset_pruebas.xlsx'\n",
    "df = pd.read_excel(ruta_archivo)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67badcd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " 'onu',\n",
       " 's.a.',\n",
       " 'cia, fbi',\n",
       " 'seat',\n",
       " 'ue, otan',\n",
       " 'ong',\n",
       " 'ocde',\n",
       " 'renfe',\n",
       " 'cfo']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_acronyms = set(df['acronyms'].str.lower().tolist())\n",
    "list(lista_acronyms)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5ce91fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class AcronymGenerator(dspy.Signature):\n",
    "    #\n",
    "    Genera un texto extenso para los acrónimos dados, asegurándose de que contenga los acrónimos dentro de un contexto simulado.\n",
    "    \n",
    "    Ejemplo:\n",
    "    --------\n",
    "    ACRÓNIMOS: [\"ONU\", \"NASA\"]\n",
    "    TEXTO_GENERADO: \"En la última reunión de la ONU, se discutieron los avances tecnológicos presentados por la NASA.\n",
    "    La ONU destacó la importancia de estos desarrollos para la exploración espacial y la cooperación internacional...\"\n",
    "    \n",
    "    ACRONIMOS = dspy.InputField(desc=\"List of acronyms in spanish that must be used to generate realistic text\")\n",
    "    TEXTO_GENERADO = dspy.OutputField(desc=\"List of acronyms in spanish that must be used to generate realistic text\")\n",
    "\"\"\"\n",
    "\n",
    "# Te he modificado esto un poco. Si haces las instrucciones en inglés, las definiciones del input y del output también deberían estar en inglés.\n",
    "# Ten en cuenta que la signature es tu prompt, simplemente la estás definiendo como una clase\n",
    "class AcronymGenerator(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Genera un texto en ESPAÑOL que contenga ACRONIMOS dentro de un contexto simulado. \n",
    "    \n",
    "    ACRONIMOS: IVA, PYME, IRPF, PIB\n",
    "    TEXTO_GENERADO: La reforma del sistema tributario ha traído cambios significativos en el IVA, afectando tanto a consumidores como a empresarios. Las PYME han mostrado preocupación por el aumento de la carga fiscal, ya que sus márgenes de beneficio son más ajustados. Por otro lado, el gobierno ha ajustado las tasas del IRPF para aliviar la presión sobre las rentas más bajas. Según los últimos informes, el PIB del país ha crecido un 2% en el último trimestre, reflejando una recuperación económica gradual. Sin embargo, los expertos advierten que es esencial seguir monitorizando estos indicadores para evitar futuros desequilibrios.\n",
    "    \"\"\"\n",
    "    \n",
    "    ACRONIMOS = dspy.InputField(desc=\"Lista de acrónimos\")\n",
    "    TEXTO_GENERADO = dspy.OutputField(desc=\"Texto generado\")\n",
    "\n",
    "    \n",
    "class AcronymGeneratorModule(dspy.Module):\n",
    "    def __init__(self, model_url, model_port):\n",
    "        super().__init__()\n",
    "        self.generator = dspy.Predict(AcronymGenerator) # para este caso de uso el Predict funciona mejor que el ChainOfThought\n",
    "        #self.lm = dspy.HFClientTGI(model=\"meta-llama/Meta-Llama-3-8B\", port=model_port, url=model_url) # esto lo he comentado porque para hacer pruebas entre usar un llm y otro me resulta más fácil cambiarlo desde fuera, pero me parece bien definirlo así\n",
    "        #dspy.settings.configure(lm=self.lm)\n",
    "\n",
    "    def forward(self, acronyms):\n",
    "        # prompt = self.create_prompt(acronyms) # No entiendo muy bien para que haces esto. ¿Por qué no usas la signature que has creado?\n",
    "        # qa = dspy.ChainOfThought('question -> answer')\n",
    "\n",
    "        # Utilizando el contexto de dspy con LLaMA\n",
    "        #with dspy.context(lm=self.lm):\n",
    "            #response = qa(question=prompt\n",
    "        \n",
    "        response = self.generator(ACRONIMOS=\", \".join(acronyms))\n",
    "        \n",
    "        #generated_text = response.answer.strip()\n",
    "        return dspy.Prediction(TEXTO_GENERADO=response.TEXTO_GENERADO)\n",
    "    \n",
    "    #def create_prompt(self, acronyms):\n",
    "    #    acronyms_str = \", \".join(acronyms)\n",
    "    #    prompt = (\n",
    "    #        f\"Genera un texto en español que incluya los siguientes acrónimos en un contexto realista y detallado: {acronyms_str}. \"\n",
    "    #        \"El texto debe ser extenso y desarrollar un escenario en el cual estos acrónimos sean relevantes. \"\n",
    "    #        \"Por favor, asegúrate de que el texto sea coherente y bien estructurado.\"\n",
    "    #    )\n",
    "    #    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5ad3d2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADN', 'ARN']\n",
      "Prediction(\n",
      "    TEXTO_GENERADO='El estudio de la genética ha avanzado significativamente gracias a la investigación en el ADN y el ARN. Estos ácidos nucleicos son fundamentales para comprender la herencia genética y el funcionamiento de los organismos vivos. Los científicos continúan explorando las posibilidades que ofrecen estas moléculas en el campo de la medicina y la biotecnología.'\n",
      ")\n",
      "['Concacaf']\n",
      "Prediction(\n",
      "    TEXTO_GENERADO='La selección nacional de fútbol ha logrado clasificar a la próxima Copa Oro de la Concacaf, demostrando un gran nivel de juego y compromiso en cada partido. Los aficionados están emocionados por ver a sus jugadores favoritos representando al país en esta importante competición regional. ¡Vamos equipo, a por la victoria en la Concacaf!'\n",
      ")\n",
      "['OVNI', 'UNESCO', 'Radar']\n",
      "Prediction(\n",
      "    TEXTO_GENERADO='Durante la última década, los avistamientos de OVNI han aumentado significativamente en todo el mundo, lo que ha llevado a la UNESCO a iniciar investigaciones para determinar si existe vida extraterrestre. Los radares de última generación han sido clave en la detección de estos objetos voladores no identificados, proporcionando datos importantes para el estudio de este fenómeno.'\n",
      ")\n",
      "['ONU', 'INE', 'OCDE', 'IBEX', 'CIP']\n",
      "Prediction(\n",
      "    TEXTO_GENERADO='La ONU ha publicado un informe en colaboración con el INE y la OCDE, destacando la importancia de políticas económicas sostenibles para el crecimiento global. En este sentido, el IBEX ha experimentado fluctuaciones debido a la incertidumbre en los mercados internacionales. Por otro lado, el CIP ha propuesto medidas para fomentar la inversión y la competitividad en el sector industrial.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "acronyms = [\n",
    "    [\"ADN\", \"ARN\"],\n",
    "    [\"Concacaf\"],\n",
    "    [\"OVNI\", \"UNESCO\", \"Radar\"],\n",
    "    [\"ONU\", \"INE\", \"OCDE\", \"IBEX\", \"CIP\"]\n",
    "]\n",
    "model_url = \"http://127.0.0.1\"  # URL del servidor del modelo LLaMA\n",
    "model_port = 8080  # Puerto del servidor del modelo LLaMA\n",
    "\n",
    "my_acronym_generator = AcronymGeneratorModule(model_url=model_url, model_port=model_port)\n",
    "for ac in acronyms:\n",
    "    print(ac)\n",
    "    #prediction = module.forward(acronyms)\n",
    "    #print(prediction.TEXTO_GENERADO)\n",
    "    print(my_acronym_generator(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "974a52a9-89f9-4843-b2a8-75d43f737122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Genera un texto en ESPAÑOL que contenga ACRONIMOS dentro de un contexto simulado. \n",
      "    \n",
      "    ACRONIMOS: IVA, PYME, IRPF, PIB\n",
      "    TEXTO_GENERADO: La reforma del sistema tributario ha traído cambios significativos en el IVA, afectando tanto a consumidores como a empresarios. Las PYME han mostrado preocupación por el aumento de la carga fiscal, ya que sus márgenes de beneficio son más ajustados. Por otro lado, el gobierno ha ajustado las tasas del IRPF para aliviar la presión sobre las rentas más bajas. Según los últimos informes, el PIB del país ha crecido un 2% en el último trimestre, reflejando una recuperación económica gradual. Sin embargo, los expertos advierten que es esencial seguir monitorizando estos indicadores para evitar futuros desequilibrios.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "ACRONIMOS: Lista de acrónimos\n",
      "TEXTO GENERADO: Texto generado\n",
      "\n",
      "---\n",
      "\n",
      "ACRONIMOS: ONU, INE, OCDE, IBEX, CIP\n",
      "TEXTO GENERADO:\u001b[32m La ONU ha publicado un informe en colaboración con el INE y la OCDE, destacando la importancia de políticas económicas sostenibles para el crecimiento global. En este sentido, el IBEX ha experimentado fluctuaciones debido a la incertidumbre en los mercados internacionales. Por otro lado, el CIP ha propuesto medidas para fomentar la inversión y la competitividad en el sector industrial.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e1b7f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to 127.0.0.1 port 8080 after 0 ms: Connection refused\n"
     ]
    }
   ],
   "source": [
    "# Para comprobar la conexión al servidor LLaMA\n",
    "!curl -X POST http://127.0.0.1:8080/generate -d '{\"prompt\": \"Hello\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filtered_samples = samples_train[samples_train['answers'].apply(lambda x: len(x) > 0)]\n",
    "df_unique_titles = filtered_samples.drop_duplicates(subset='title', keep='first')\n",
    "df_unique_titles.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_samples = []\n",
    "for idx, el in df_unique_titles.iterrows():\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"-- -- Processing index {idx} out of {len(df_unique_titles)}\")\n",
    "    cherry_picker = negator(question=el.question, golden_answer=el.answers[0][\"text\"])\n",
    "    new_samples.append(\n",
    "        [\n",
    "            el.question, # question\n",
    "            el.answers[0][\"text\"], # answer1\n",
    "            cherry_picker.CHERRY_ANSWER, # answer2\n",
    "            \"CONTRADICTION\", # label\n",
    "            cherry_picker.RATIONALE, # rationale\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Convert new_samples to a DataFrame if needed\n",
    "new_samples_df = pd.DataFrame(new_samples, columns=['question', 'answer1', 'answer2', 'label', 'rationale'])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
