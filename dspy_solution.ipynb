{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "THdnNr6dZtt6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re, time, random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "import pathlib\n",
    "import chromadb\n",
    "\n",
    "import dspy\n",
    "import dsp\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CVxP_bggZziC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected request with `Content-Type: application/json`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Para comprobar la conexión al servidor LLaMA\n",
    "!curl -X POST http://127.0.0.1:8090/generate -d '{\"prompt\": \"Hello\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fQ1BowOSZzpr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/usuarios_ml4ds/cggamella/NP-Search-Tool/.env\n",
      "/export/usuarios_ml4ds/cggamella/NP-Search-Tool/.env\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#   LLM   #\n",
    "###########\n",
    "path_env = pathlib.Path(\"/export/usuarios_ml4ds/cggamella/NP-Search-Tool/.env\")\n",
    "print(path_env)\n",
    "load_dotenv(path_env)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "lm = dspy.HFClientTGI(model=\"meta-llama/meta-llama-3-8b-instruct\", port=8090, url=\"http://127.0.0.0\") #\"meta-llama/Meta-Llama-3-8B \"\n",
    "#lm = dspy.OpenAI(model=\"gpt-3.5-turbo\")# \"gpt-4o-2024-05-13\")\n",
    "\n",
    "path_env = pathlib.Path(\"/export/usuarios_ml4ds/cggamella/NP-Search-Tool/.env\")\n",
    "print(path_env)\n",
    "load_dotenv(path_env)\n",
    "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = api_key\n",
    "\n",
    "dspy.settings.configure(lm=lm, temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EQhF760Z7_G"
   },
   "source": [
    "# Detección de acrónimos con dspy  (Etapa 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WWDvEZYMZzso",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ruta_archivo = '/export/usuarios_ml4ds/cggamella/RAG_tool/acronyms_paper.xlsx'\n",
    "df = pd.read_excel(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WU-McKRDZzvj",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acronyms', 'manual_expanded_acronyms', 'text',\n",
       "       'detected_acronyms_LLaMA', 'expanded_LLaMA', 'expanded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8tKx4TAJZzyW",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronyms</th>\n",
       "      <th>manual_expanded_acronyms</th>\n",
       "      <th>text</th>\n",
       "      <th>detected_acronyms_LLaMA</th>\n",
       "      <th>expanded_LLaMA</th>\n",
       "      <th>expanded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ONG</td>\n",
       "      <td>Organización no gubernamental</td>\n",
       "      <td>la ong ha lanzado una campaña de concienciació...</td>\n",
       "      <td>ONG</td>\n",
       "      <td>Organización No Gubernamental</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCAP</td>\n",
       "      <td>Pliego de cláusulas administrativas particulares</td>\n",
       "      <td>el contrato de obra pública se regirá por el p...</td>\n",
       "      <td>PCAP</td>\n",
       "      <td>pliego de cláusulas administrativas particulares</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acronyms                          manual_expanded_acronyms  \\\n",
       "0      ONG                     Organización no gubernamental   \n",
       "1     PCAP  Pliego de cláusulas administrativas particulares   \n",
       "\n",
       "                                                text detected_acronyms_LLaMA  \\\n",
       "0  la ong ha lanzado una campaña de concienciació...                     ONG   \n",
       "1  el contrato de obra pública se regirá por el p...                    PCAP   \n",
       "\n",
       "                                     expanded_LLaMA  expanded  \n",
       "0                     Organización No Gubernamental       NaN  \n",
       "1  pliego de cláusulas administrativas particulares       NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "J_zhhZmlZz1C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AcronymDetector(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Detecta los acrónimos, abreviaturas y siglas que contenga el texto.\n",
    "\n",
    "    TEXTO: La reforma del sistema tributario ha traído cambios significativos en el IVA,\n",
    "    afectando tanto a consumidores como a empresarios. Las PYME han mostrado preocupación por el aumento\n",
    "    de la carga fiscal, ya que sus márgenes de beneficio son más ajustados. Por otro lado, el gobierno ha\n",
    "    ajustado las tasas del IRPF para aliviar la presión sobre las rentas más bajas. Según los últimos informes,\n",
    "    el PIB del país ha crecido un 2% en el último trimestre, reflejando una recuperación económica gradual.\n",
    "    Sin embargo, los expertos advierten que es esencial seguir monitorizando estos indicadores para evitar futuros desequilibrios.\n",
    "    ACRONIMOS:IVA, PYME, IRPF, PIB\n",
    "    \"\"\"\n",
    "\n",
    "    TEXTO = dspy.InputField(desc=\"Texto en español que puede contener o no, acrónimos, siglas y/o abreviaturas que deben detectarse\")\n",
    "    ACRONIMOS = dspy.OutputField(desc=\"Lista de acrónimos, siglas y/o abreviaturas. Un acrónimo, es un tipo de palabra formada a partir de la fusión de varias palabras.\")\n",
    "\n",
    "class AcronymDetectorModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = dspy.Predict(AcronymDetector)\n",
    "\n",
    "    def forward(self, texto):\n",
    "        response = self.generator(TEXTO=texto)\n",
    "        return dspy.Prediction(ACRONIMOS=response.ACRONIMOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeqcliFzaDy0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear una instancia del módulo\n",
    "my_acronym_detector = AcronymDetectorModule()\n",
    "\n",
    "# Lista para almacenar los acrónimos detectados\n",
    "acronyms_detected = []\n",
    "\n",
    "# Detectar acrónimos en cada texto del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing row {index}: {row['text']}\")\n",
    "    prediction = my_acronym_detector.forward(row['text'])\n",
    "    print(f\"Detected acronyms: {prediction.ACRONIMOS}\")\n",
    "    acronyms_detected.append(prediction.ACRONIMOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6UxeHb2_aD18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Guardar los acrónimos detectados\n",
    "df['detected_acronyms_LLaMA'] = acronyms_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Rp8Lo3KaD4p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm.inspect_history(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGtXed7aaKEa"
   },
   "source": [
    "# Nueva forma de hacer chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ebDuTKf6aD7D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# La modifico incluyendo como parámetro el window_overlap para intanciarla con mayor control y ajuste del final del doc\n",
    "class Chunker:\n",
    "    def __init__(self, context_window=3000, max_windows=5, window_overlap = 0.02):\n",
    "        self.context_window = context_window\n",
    "        self.max_windows = max_windows\n",
    "        self.window_overlap = window_overlap\n",
    "\n",
    "    def __call__(self, paper):\n",
    "        snippet_idx = 0\n",
    "        startpos = 0\n",
    "\n",
    "        while snippet_idx < self.max_windows and len(paper) > startpos:\n",
    "            endpos = startpos + int(self.context_window * (1.0 + self.window_overlap))\n",
    "            if endpos > len(paper):\n",
    "                endpos = len(paper)\n",
    "            snippet = paper[startpos:endpos]\n",
    "\n",
    "            next_newline_pos = snippet.rfind('\\n')\n",
    "            if next_newline_pos != -1 and next_newline_pos >= self.context_window // 2:\n",
    "                snippet = snippet[:next_newline_pos + 1]\n",
    "\n",
    "            yield snippet_idx, snippet.strip()\n",
    "            startpos += self.context_window - int(self.context_window * self.window_overlap)\n",
    "            snippet_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ws64zZCXaNYX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunker = Chunker(context_window=3000, max_windows=100, window_overlap = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lv3mgSImaNbU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalizar el campo textual para evitar problemas\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    example_document = row['text']\n",
    "    print(\"EXAMPLE DOC:\\n\",example_document)\n",
    "    doc = Document(page_content=example_document, metadata={\"url\": \"local\", \"source\": \"initial\"})\n",
    "    print(\"El DOC es:\\n\",doc)\n",
    "\n",
    "    # Dividir el documento en fragmentos usando la instancia de Chunker\n",
    "    for _, chunk in chunker(doc.page_content):\n",
    "        chunk_doc = Document(page_content=chunk, metadata=doc.metadata)\n",
    "        print(\"EL chunk_doc es:\\n\",chunk_doc)\n",
    "        documents.append(chunk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS-_kMXzaNd-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqaB7YelaNgH"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Normalizar el campo textual para evitar problemas\n",
    "df['text'] = df['text'].str.lower()\n",
    "# Crear el text splitter, [chunk_size: #caracteres de cada chunk];\n",
    "#[chunk_overlap: #caracteres solapan entre chunks para no perder info.]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "\n",
    "# Crear una lista para almacenar los documentos\n",
    "documents = []\n",
    "# Procesar cada fila como un documento separado\n",
    "for idx, row in df.iterrows():\n",
    "    example_document = row['text']\n",
    "    print(\"el example doc es:\",example_document)\n",
    "    doc = Document(page_content=example_document, metadata={\"url\": \"local\", \"source\": \"initial\"}) #, \"identifier\": row['identifier']})\n",
    "    print(\"El doc es:\",doc)\n",
    "    # Dividir el documento en fragmentos\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    print(\"Los chunks son:\",chunks)\n",
    "    for chunk in chunks:\n",
    "        chunk_doc = Document(page_content=chunk, metadata=doc.metadata)\n",
    "        print(\"EL chunk_doc es:\\n\",chunk_doc)\n",
    "        documents.append(chunk_doc)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrjhfDDdaWw4"
   },
   "source": [
    "# Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxHpEY60aVva"
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "path_to_index = '/export/usuarios_ml4ds/cggamella/RAG_tool'\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = (pathlib.Path(path_to_index) / 'db_POC_acronyms').as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgHByhxhaVya"
   },
   "outputs": [],
   "source": [
    "# Calcular los embeddings con un modelo de uso libre de HuggingFace\n",
    "# Using HuggingFace models\n",
    "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "    api_key=\"HUGGINGFACE_API_KEY\",\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name)\n",
    "\n",
    "start = time.time()\n",
    "# Almacenar los fragmentos en Chroma\n",
    "# Se extrae el contenido (page_content).El contenido se pasa al modelo de embeddings.\n",
    "# El vector resultante se almacena en la base de datos junto con los metadatos(índices).\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Total time is {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chroma db without Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "path_to_index = '/export/usuarios_ml4ds/cggamella/RAG_tool/example1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomEmbeddings():\n",
    "\n",
    "    def __init__(self, model='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        self.model = SentenceTransformer(model)\n",
    "        \n",
    "    def encode(self, texts):\n",
    "        return self.model.encode(texts)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.encode(input)\n",
    "    \n",
    "embedding_model = CustomEmbeddings('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "client = chromadb.PersistentClient(path=path_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(name=\"test1\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunker = Chunker(context_window=3000, max_windows=100, window_overlap = 0.1)\n",
    "\n",
    "def addVectorDataToDb(df, chunker) -> None:\n",
    "    embeddings: list = []\n",
    "    metadatas: list = []\n",
    "    documents: list = []\n",
    "    ids: list = []\n",
    "    \n",
    "    df['text'] = df['text'].str.lower() # Normalizar el campo textual para evitar problemas\n",
    "    \n",
    "    try:\n",
    "        for idx, row in df.iterrows():      \n",
    "            # divide in chunks\n",
    "            for id_chunk, chunk in chunker(row.text):\n",
    "                embeddings.append(embedding_model.encode(chunk).tolist())\n",
    "                #metadatas.append(f\"{str(idx)}_{str(id_chunk)}\")\n",
    "                documents.append(chunk)\n",
    "                ids.append(f\"{str(idx)}_{str(id_chunk)}\")\n",
    "        collection.add(\n",
    "            embeddings=embeddings,\n",
    "            #metadatas=metadatas,\n",
    "            documents=documents,\n",
    "            ids=ids\n",
    "        )\n",
    "        print(\"Data added to collection\")\n",
    "    except Exception as e:\n",
    "        print(\"Add data to db failed : \", e)\n",
    "        \n",
    "addVectorDataToDb(df, chunker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def searchDataByVector(query: str):\n",
    "    try:\n",
    "        query_vector = embedding_model.encode(query).tolist()\n",
    "        res = collection.query(\n",
    "            query_embeddings=[query_vector],\n",
    "            n_results=1,\n",
    "            include=['distances','embeddings', 'documents'],\n",
    "        )\n",
    "        print(\"Query\", \"\\n--------------\")\n",
    "        print(query)\n",
    "        print(\"Result\", \"\\n--------------\")\n",
    "        print(res['documents'][0][0])\n",
    "        print(\"Vector\", \"\\n--------------\")\n",
    "        print(res['embeddings'][0][0])\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"Complete Response\",\"\\n-------------------------\")\n",
    "        print(res)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Vector search failed : \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_pdf_1 = \"El PDF, formato de documento portátil, se ha convertido en un estándar para la distribución de documentos en línea. Permite a los usuarios compartir información de manera segura y profesional, preservando el formato original independientemente del software o dispositivo utilizado para su visualización.\"\n",
    "example_pdf_2 = \"En el campo de la ingeniería, es crucial para evaluar la fiabilidad de estructuras y materiales. Ayuda a los ingenieros a modelar y prever el comportamiento de sistemas complejos mediante el análisis de la distribución de probabilidades. Desde la planificación de proyectos hasta la gestión de riesgos, la PDF proporciona herramientas poderosas para optimizar el diseño y la operación de infraestructuras críticas.\"\n",
    "\n",
    "searchDataByVector(query=\"formato de documento portátil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFLg_jhPaeBt"
   },
   "source": [
    "# Cargar la bbdd ya creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNvVyIdXaV1A"
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODPyv6FyaV3o"
   },
   "outputs": [],
   "source": [
    "results = vectordb.get(limit=1, include=['documents', 'embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dHmSBt5aiCX"
   },
   "outputs": [],
   "source": [
    "query_vector = embedding_model.encode(query).tolist()\n",
    "res = collection.query(\n",
    "    query_embeddings=[query_vector],\n",
    "    n_results=1,\n",
    "    include=['distances','embeddings', 'documents', 'metadatas'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10xTtgTaaiMX"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv4My9HtannH"
   },
   "source": [
    "# Custom Retrieval Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "bUBKAkUOalis",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AcronymAwareRetriever(dspy.Retrieve):\n",
    "    \"\"\"\n",
    "    Custom retriever for searching documents containing a specific acronym.\n",
    "    \"\"\"\n",
    "    def __init__(self, vectordb, k:int = 3):\n",
    "        super().__init__(k=k)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, acronym: Union[str, List[str]], k: int = None) -> dspy.Prediction:\n",
    "        \"\"\"\n",
    "        Retrieve documents containing the provided acronym by directly querying\n",
    "        the vector database. The documents are filtered to include only those\n",
    "        where the acronym appears as a standalone word.\n",
    "        \"\"\"\n",
    "        # Creating regex to match the acronym as a standalone word\n",
    "        regex = r'\\b' + re.escape(acronym) + r'\\b'\n",
    "\n",
    "        # Retrieve documents that might contain the acronym\n",
    "        results = self.vectordb.get(where_document={\"$contains\": acronym}, limit=k if k else self.k,\n",
    "                                    include=['documents', 'embeddings'])\n",
    "\n",
    "        # Extract relevant information\n",
    "        documents = results.get('documents', [])\n",
    "        embeddings = results.get('embeddings', [])\n",
    "\n",
    "         # Filter documents and their embeddings using regex, avoiding duplicates\n",
    "        seen_documents = set()\n",
    "        filtered_documents = []\n",
    "        filtered_embeddings = []\n",
    "        filtered_passages = []\n",
    "\n",
    "        for doc, emb in zip(documents, embeddings):\n",
    "            # Check if the document contains the acronym as a standalone word and is not already added\n",
    "            if re.search(regex, doc, re.IGNORECASE) and doc not in seen_documents:\n",
    "                seen_documents.add(doc)\n",
    "                filtered_documents.append(doc)\n",
    "                filtered_embeddings.append(emb)\n",
    "                # Extract passages for documents that pass the regex check\n",
    "                filtered_passages.append(self.extract_passages(doc, acronym))\n",
    "\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            documents=filtered_documents,\n",
    "            embeddings=filtered_embeddings,\n",
    "            passages=filtered_passages\n",
    "        )\n",
    "\n",
    "    def extract_passages(self, text, acronym):\n",
    "        \"\"\"\n",
    "        Extract the two preceding and two following sentences after the first appearance of the acronym in\n",
    "        the text.\n",
    "        \"\"\"\n",
    "        sentences = sent_tokenize(text)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if acronym.lower() in sentence.lower():\n",
    "                start = max(i - 2, 0)\n",
    "                end = min(i + 3, len(sentences))\n",
    "                return ' '.join(sentences[start:end])\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MagGc9-eatHp"
   },
   "source": [
    "# Desambiguación de acrónimos con dspy (Etapa 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XvHJutwBall2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AcronymExpander(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Expande los acrónimos basándose en el contexto del texto.\n",
    "\n",
    "    TEXTO: Las antenas que operan en la banda de los 60 Ghz se dice que funcionan en la banda de ondas milimétricas, pues bien su longitud de onda está en el orden de los milímetros.\n",
    "\n",
    "    ACRONIMO: ghz\n",
    "    EXPANSION: gigahercio\n",
    "    \"\"\"\n",
    "\n",
    "    TEXTO = dspy.InputField(desc=\"Texto que contiene el acrónimo,sigla o abreviatura y aporta información sobre la forma expandida\")\n",
    "    ACRONIMO = dspy.InputField(desc=\"Acrónimo que necesita ser expandido\")\n",
    "    EXPANSION = dspy.OutputField(desc=\"Es la forma expandida del acrónimo\")\n",
    "\n",
    "class AcronymExpanderModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.expander = dspy.Predict(AcronymExpander)\n",
    "        self.expander = dspy.ChainOfThought(AcronymExpander)\n",
    "\n",
    "    def forward(self, texto, acronimo):\n",
    "        response = None\n",
    "        try:\n",
    "            response = self.expander(TEXTO=texto, ACRONIMO=acronimo)\n",
    "            print(f\"En el forward la respuesta para el texto '{texto}' es:{response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"-- -- Error expanding acronym: {e}\")\n",
    "            response = None\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            texto=texto,\n",
    "            acronimo=acronimo,\n",
    "            expansion=response.EXPANSION if response else None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "nmXONClUaloe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el forward la respuesta para el texto 'Ejemplo de texto' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Ejemplo de texto'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Uso del módulo\n",
    "module = AcronymExpanderModule()\n",
    "result = module.forward(texto=\"Ejemplo de texto\", acronimo=\"Ej\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q51GHUqayzJ"
   },
   "source": [
    "# Disambiguation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb=collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Jtwy2QsAalq_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "acronym_retriever = AcronymAwareRetriever(vectordb=vectordb, k=5)\n",
    "acronym_expander = AcronymExpanderModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1oGbuJDVa1Ho",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ong']\n",
      "En el forward la respuesta para el texto 'la ong ha lanzado una campaña de concienciación sobre la importancia de la protección del medio ambiente. la organización no gubernamental ha trabajado en colaboración con diferentes entidades para promover la sostenibilidad y la conservación de la biodiversidad. gracias al apoyo de voluntarios y donantes, la ong ha logrado implementar proyectos de reforestación y limpieza de playas en todo el país.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='organización no gubernamental'\n",
      ")\n",
      "['pcap']\n",
      "En el forward la respuesta para el texto 'el contrato de obra pública se regirá por el pliego de cláusulas administrativas particulares (pcap), el cual establece las condiciones específicas que deben cumplir tanto la administración como la empresa contratista. es fundamental revisar detenidamente el pcap para garantizar el cumplimiento de todas las obligaciones y evitar posibles conflictos durante la ejecución del proyecto.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='pliego de cláusulas administrativas particulares'\n",
      ")\n",
      "['otan']\n",
      "En el forward la respuesta para el texto 'la otan es una organización internacional que tiene como objetivo principal garantizar la seguridad y defensa de sus países miembros. desde su creación, la otan ha desempeñado un papel crucial en la estabilidad y la paz mundial, colaborando estrechamente en misiones de mantenimiento de la paz y en la lucha contra el terrorismo. gracias a la cooperación entre los países miembros de la otan, se ha logrado fortalecer la seguridad colectiva y promover la democracia en todo el mundo.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Organización del Tratado del Atlántico Norte'\n",
      ")\n",
      "['ghz']\n",
      "En el forward la respuesta para el texto 'el nuevo teléfono móvil cuenta con un procesador de última generación que alcanza una velocidad de 2.5 ghz, lo que significa que puede ejecutar aplicaciones de forma más rápida y eficiente. con esta tecnología, los usuarios podrán disfrutar de una experiencia más fluida y sin interrupciones en sus actividades diarias.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='gigahercio'\n",
      ")\n",
      "['fnupi']\n",
      "En el forward la respuesta para el texto 'el fnupi (fondo de las naciones unidas para la infancia) ha lanzado una campaña para concienciar sobre la importancia de la educación infantil en países en desarrollo. el objetivo es garantizar que todos los niños tengan acceso a una educación de calidad y puedan desarrollar todo su potencial. gracias al apoyo de organizaciones internacionales, el fnupi ha logrado ampliar su alcance y llegar a más comunidades vulnerables.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='fondo de las naciones unidas para la infancia'\n",
      ")\n",
      "['ue']\n",
      "['fmi']\n",
      "En el forward la respuesta para el texto 'el fmi (fondo monetario internacional) ha recomendado al gobierno implementar medidas de austeridad para reducir el déficit fiscal. esta propuesta ha generado controversia entre los ciudadanos, quienes temen que las políticas de ajuste afecten negativamente a la economía. sin embargo, algunos expertos señalan que las recomendaciones del fmi son necesarias para garantizar la estabilidad financiera del país a largo plazo.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='fondo monetario internacional'\n",
      ")\n",
      "['oms']\n",
      "En el forward la respuesta para el texto 'la organización mundial de la salud (oms) ha emitido nuevas recomendaciones para combatir la propagación del virus. es importante seguir las directrices de la oms para proteger la salud de la población y evitar un aumento en los casos de contagio.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Organización Mundial de la Salud'\n",
      ")\n",
      "['ceip']\n",
      "En el forward la respuesta para el texto 'el ceip (centro de educación infantil y primaria) de la localidad ha implementado un nuevo programa de actividades extracurriculares para fomentar el desarrollo integral de los alumnos. los padres y madres de los estudiantes han mostrado gran interés en estas iniciativas, que van desde talleres de arte hasta clases de idiomas. el ceip se ha convertido en un referente en la comunidad por su enfoque innovador en la educación de los más pequeños.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='centro de educación infantil y primaria'\n",
      ")\n",
      "['itv']\n",
      "En el forward la respuesta para el texto 'la itv es un trámite obligatorio para todos los vehículos en circulación. la inspección técnica de vehículos garantiza que los automóviles cumplan con los requisitos de seguridad y emisiones establecidos por la normativa vigente. es importante programar la itv con antelación para evitar multas y asegurar la correcta operatividad del vehículo en la vía pública.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='inspección técnica de vehículos'\n",
      ")\n",
      "['tve']\n",
      "En el forward la respuesta para el texto 'la programación de televisión española ha sido criticada recientemente por su falta de diversidad y calidad. muchos espectadores se quejan de la saturación de reality shows y la escasez de contenido cultural. a pesar de los esfuerzos por mejorar la imagen de tve, la audiencia sigue disminuyendo. los directivos de la cadena están buscando nuevas estrategias para aumentar la audiencia y recuperar la confianza del público.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Televisión Española'\n",
      ")\n",
      "['s.a.']\n",
      "['vp']\n",
      "En el forward la respuesta para el texto 'el vicepresidente vp de la empresa presentó el informe de ventas del último trimestre, destacando el crecimiento del volumen de ventas y la mejora en la rentabilidad.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='vicepresidente'\n",
      ")\n",
      "['pk']\n",
      "En el forward la respuesta para el texto 'el accidente ocurrió en el pk 50 de la autopista, causando un gran congestionamiento de tráfico. los servicios de emergencia llegaron rápidamente al lugar para atender a los heridos y restablecer la circulación. la policía investiga las causas del suceso para determinar si hubo alguna negligencia por parte de los conductores involucrados.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='kilómetro'\n",
      ")\n",
      "['pyme', ' pib']\n",
      "En el forward la respuesta para el texto 'la ley de apoyo a las pyme ha sido aprobada por el gobierno para impulsar el crecimiento económico y la creación de empleo. las pequeñas y medianas empresas son fundamentales para la economía del país, representando una gran parte del pib. con esta medida, se busca facilitar el acceso al financiamiento y reducir la carga fiscal para las pyme, fomentando así su desarrollo y competitividad en el mercado nacional e internacional. la ocde (organización para la cooperación y el desarrollo económicos) ha publicado un informe que destaca la importancia de implementar reformas estructurales para impulsar el crecimiento económico. según el análisis de la ocde, es fundamental mejorar la eficiencia en el uso de los recursos y promover la innovación en las pyme. además, se recomienda una mayor coordinación entre los países miembros para abordar los desafíos globales en materia de comercio y medio ambiente.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='pequeñas y medianas empresas'\n",
      ")\n",
      "En el forward la respuesta para el texto 'la ley de apoyo a las pyme ha sido aprobada por el gobierno para impulsar el crecimiento económico y la creación de empleo. las pequeñas y medianas empresas son fundamentales para la economía del país, representando una gran parte del pib. con esta medida, se busca facilitar el acceso al financiamiento y reducir la carga fiscal para las pyme, fomentando así su desarrollo y competitividad en el mercado nacional e internacional.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Producto Interno Bruto'\n",
      ")\n",
      "['ccaa', ' virus']\n",
      "En el forward la respuesta para el texto 'las diferentes ccaa han implementado medidas para contener la propagación del virus, adaptándose a las necesidades específicas de cada región.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='comunidades autónomas'\n",
      ")\n",
      "En el forward la respuesta para el texto 'las diferentes ccaa han implementado medidas para contener la propagación del virus, adaptándose a las necesidades específicas de cada región. la organización mundial de la salud (oms) ha emitido nuevas recomendaciones para combatir la propagación del virus. es importante seguir las directrices de la oms para proteger la salud de la población y evitar un aumento en los casos de contagio.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='virus de la covid-19'\n",
      ")\n",
      "['cnmv']\n",
      "En el forward la respuesta para el texto 'la comisión nacional del mercado de valores (cnmv) es el organismo encargado de supervisar e inspeccionar los mercados de valores en españa. su principal objetivo es garantizar la transparencia y la protección de los inversores, velando por el correcto funcionamiento de los mercados financieros. la cnmv se encarga de regular la actividad de las entidades financieras y de velar por el cumplimiento de la normativa vigente en materia de valores.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='comisión nacional del mercado de valores'\n",
      ")\n",
      "['minhac']\n",
      "En el forward la respuesta para el texto 'el ministerio de hacienda y administraciones públicas (minhac) ha anunciado nuevas medidas para mejorar la eficiencia en la gestión de los recursos públicos. estas acciones buscan optimizar el uso de los fondos y garantizar una mayor transparencia en el manejo de los mismos. además, se ha implementado un plan de formación para los funcionarios con el objetivo de fortalecer sus capacidades en materia financiera.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='ministerio de hacienda y administraciones públicas'\n",
      ")\n",
      "['spee']\n",
      "En el forward la respuesta para el texto 'el spee es el encargado de gestionar el empleo en españa, facilitando la inserción laboral de los ciudadanos. gracias a sus programas de formación y orientación, el spee ayuda a reducir la tasa de desempleo en el país. además, colabora estrechamente con las empresas para promover la contratación de trabajadores a través de medidas como los incentivos a la contratación.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='Servicio Público de Empleo Estatal'\n",
      ")\n",
      "['once']\n",
      "En el forward la respuesta para el texto 'la organización nacional de ciegos españoles (once) es una institución que trabaja para la integración social y laboral de las personas con discapacidad visual. a través de sus programas de formación y empleo, la once ayuda a mejorar la calidad de vida de este colectivo. además, su lotería solidaria es una fuente importante de financiación para sus proyectos.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='organización nacional de ciegos españoles'\n",
      ")\n",
      "['ocde', ' pyme']\n",
      "En el forward la respuesta para el texto 'la ocde (organización para la cooperación y el desarrollo económicos) ha publicado un informe que destaca la importancia de implementar reformas estructurales para impulsar el crecimiento económico. según el análisis de la ocde, es fundamental mejorar la eficiencia en el uso de los recursos y promover la innovación en las pyme. además, se recomienda una mayor coordinación entre los países miembros para abordar los desafíos globales en materia de comercio y medio ambiente.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='organización para la cooperación y el desarrollo económicos'\n",
      ")\n",
      "En el forward la respuesta para el texto 'la ley de apoyo a las pyme ha sido aprobada por el gobierno para impulsar el crecimiento económico y la creación de empleo. las pequeñas y medianas empresas son fundamentales para la economía del país, representando una gran parte del pib. con esta medida, se busca facilitar el acceso al financiamiento y reducir la carga fiscal para las pyme, fomentando así su desarrollo y competitividad en el mercado nacional e internacional. la ocde (organización para la cooperación y el desarrollo económicos) ha publicado un informe que destaca la importancia de implementar reformas estructurales para impulsar el crecimiento económico. según el análisis de la ocde, es fundamental mejorar la eficiencia en el uso de los recursos y promover la innovación en las pyme. además, se recomienda una mayor coordinación entre los países miembros para abordar los desafíos globales en materia de comercio y medio ambiente.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='pequeñas y medianas empresas'\n",
      ")\n",
      "['boe', ' ab', ' bc']\n",
      "En el forward la respuesta para el texto 'el boletín oficial del estado (boe) publicó hoy una nueva normativa que afecta a las empresas del sector financiero. la asociación de bancos (ab) ha expresado su preocupación por las implicaciones de esta medida en sus operaciones diarias. sin embargo, el banco central (bc) ha asegurado que estas regulaciones son necesarias para garantizar la estabilidad del sistema financiero.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='boletín oficial del estado'\n",
      ")\n",
      "En el forward la respuesta para el texto 'el boletín oficial del estado (boe) publicó hoy una nueva normativa que afecta a las empresas del sector financiero. la asociación de bancos (ab) ha expresado su preocupación por las implicaciones de esta medida en sus operaciones diarias. sin embargo, el banco central (bc) ha asegurado que estas regulaciones son necesarias para garantizar la estabilidad del sistema financiero. los analistas financieros están evaluando el impacto de estas nuevas normas en el mercado y se espera que emitan un informe detallado en los próximos días.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='banco central'\n",
      ")\n",
      "['aena']\n",
      "En el forward la respuesta para el texto 'la privatización de aena ha generado controversia en el sector aeronáutico. a pesar de las críticas, la empresa ha logrado aumentar sus beneficios y mejorar la calidad de sus servicios. sin embargo, algunos trabajadores han expresado su preocupación por posibles recortes en sus condiciones laborales.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='aeropuertos españoles'\n",
      ")\n",
      "['renfe', ' covid-19']\n",
      "En el forward la respuesta para el texto 'la empresa de transporte ferroviario renfe ha anunciado la incorporación de trenes de alta velocidad en varias rutas, con el objetivo de mejorar la conectividad entre ciudades y reducir los tiempos de viaje. esta medida forma parte de su plan de modernización y expansión, que busca aumentar la satisfacción de los usuarios y fomentar el uso del transporte público. además, renfe ha implementado nuevas medidas de seguridad y limpieza en sus estaciones y trenes, en respuesta a la pandemia de covid-19.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='red nacional de ferrocarriles españoles'\n",
      ")\n",
      "En el forward la respuesta para el texto 'la empresa de transporte ferroviario renfe ha anunciado la incorporación de trenes de alta velocidad en varias rutas, con el objetivo de mejorar la conectividad entre ciudades y reducir los tiempos de viaje. esta medida forma parte de su plan de modernización y expansión, que busca aumentar la satisfacción de los usuarios y fomentar el uso del transporte público. además, renfe ha implementado nuevas medidas de seguridad y limpieza en sus estaciones y trenes, en respuesta a la pandemia de covid-19.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='coronavirus disease 2019'\n",
      ")\n",
      "['rne']\n",
      "En el forward la respuesta para el texto 'la emisora de radio nacional españa ha lanzado una nueva campaña para promover la diversidad cultural en sus programas. con el objetivo de llegar a un público más amplio, la rne ha incorporado contenidos variados que abarcan desde música tradicional hasta debates políticos. esta estrategia ha sido bien recibida por la audiencia, que valora la calidad y la pluralidad de la programación ofrecida por la emisora. sin duda, la rne se ha consolidado como un referente en el ámbito de la radiodifusión en españa.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='radio nacional de españa'\n",
      ")\n",
      "['rrhh']\n",
      "En el forward la respuesta para el texto 'el departamento de rrhh ha implementado nuevas políticas para mejorar la retención de talento en la empresa. los empleados han expresado su satisfacción con las medidas tomadas, lo que ha llevado a un aumento en la productividad y en la satisfacción laboral. sin embargo, es importante seguir monitoreando los resultados para asegurar que las estrategias implementadas estén teniendo el impacto deseado.' es:Prediction(\n",
      "    rationale='${produce the EXPANSION}. We...',\n",
      "    EXPANSION='recursos humanos'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creo nueva columna en el df para guardar los acrónimos expandidos\n",
    "df['expanded_LLaMA'] = 'None'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    # Los acrónimos están separados por comas si se detecta más de uno.\n",
    "    detected_acronyms = str(row['detected_acronyms_LLaMA']).lower().split(',')\n",
    "    print(detected_acronyms)\n",
    "    detected_acronyms = [acronym.strip() for acronym in detected_acronyms if acronym.strip() not in ['', 'n/a', 'none', 'ninguno']]\n",
    "\n",
    "    # Lista para expansiones de acrónimos encontrados\n",
    "    expansions = []\n",
    "\n",
    "    for acronym in detected_acronyms:\n",
    "        # Recuperar documentos relevantes utilizando el retriever\n",
    "        retrieved_docs = acronym_retriever.forward(acronym).passages\n",
    "\n",
    "        # Concatenar todos los docs retrieval\n",
    "        concatenated_docs = \" \".join(retrieved_docs)\n",
    "        # Usar docs concatenados\n",
    "        if concatenated_docs:\n",
    "            expansion_result = acronym_expander.forward(concatenated_docs, acronym)\n",
    "            expansions.append(expansion_result.expansion)\n",
    "\n",
    "    # Guardar las expansiones en la columna 'expanded_LLaMA'\n",
    "    df.at[index, 'expanded_LLaMA'] = ', '.join(expansions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4fVn4o0a5ab"
   },
   "source": [
    "# Integración de grafos de conocimiento para desambiguación de contextos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aALs3iVta1KQ"
   },
   "outputs": [],
   "source": [
    "class GraphVisualizer:\n",
    "    def __init__(self, kernel='umbral', threshold=0.21, remove_self_links=True):\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        #self.symmetric = symmetric\n",
    "        self.remove_self_links = remove_self_links\n",
    "\n",
    "    def set_embeddings(self, embeddings):\n",
    "        self.embeddings = np.array(embeddings)\n",
    "\n",
    "    def _get_similarity_matrix(self):\n",
    "        if self.embeddings is None:\n",
    "            raise ValueError(\"Please set embeddings before trying to get similarity matrix.\")\n",
    "        #print(type(self.embeddings), self.embeddings.shape)\n",
    "        print(self.embeddings)\n",
    "        similarity_matrix = cosine_similarity(self.embeddings)\n",
    "        print(\"La matriz de similitud es:\\n\", similarity_matrix)\n",
    "        if self.kernel == \"umbral\":\n",
    "            similarity_matrix[similarity_matrix < self.threshold] = 0\n",
    "        if self.remove_self_links:\n",
    "            np.fill_diagonal(similarity_matrix, 0)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def visualize_graph(self, plot_graph=True):\n",
    "        similarity_matrix = self._get_similarity_matrix()\n",
    "        G = nx.from_numpy_array(similarity_matrix, create_using=nx.DiGraph)\n",
    "\n",
    "        if plot_graph:\n",
    "            pos = nx.spring_layout(G, seed=42)\n",
    "            nx.draw(G, pos, node_color='skyblue', with_labels=True, node_size=70, edge_color='blue', width=0.4)\n",
    "            plt.title(\"Document Similarity Graph\")\n",
    "            plt.show()\n",
    "\n",
    "        return {\n",
    "            'number_of_nodes': G.number_of_nodes(),\n",
    "            'number_of_edges': G.number_of_edges(),\n",
    "            'edges_per_node': G.number_of_edges() / G.number_of_nodes()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hrw7th35a1Mq"
   },
   "outputs": [],
   "source": [
    "result_predict = acronym_retriever.forward(\"pdf\")\n",
    "\n",
    "\n",
    "# Instanciar y configurar GraphVisualizer\n",
    "visualizer = GraphVisualizer(kernel='umbral', threshold=0.31, remove_self_links=True)\n",
    "visualizer.set_embeddings(result_predict.embeddings)\n",
    "\n",
    "# Visualizar el grafo de similitud\n",
    "visualizer.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNZLNFsfbBLR"
   },
   "source": [
    "# Crear dataset de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdhlbxhkbA2i"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def create_dtset_expanded_acronyms(excel_path):\n",
    "    # Cargar datos\n",
    "    df = pd.read_excel(excel_path)\n",
    "    df = df[['acronyms', 'manual_expanded_acronyms', 'text']]\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y validación\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convertir los df de train y dev en listas de diccionarios\n",
    "    data_train = train_df.to_dict('records')\n",
    "    data_test = test_df.to_dict('records')\n",
    "\n",
    "    # Create train examples\n",
    "    trainset = [\n",
    "        dspy.Example({'texto': row['text'], 'acronimos': row['acronyms'], 'expansion': {row['acronyms']: row['manual_expanded_acronyms']}}) for row in data_train\n",
    "    ]\n",
    "    # Create dev examples\n",
    "    devset = [\n",
    "        dspy.Example({'texto': row['text'], 'acronimos': row['acronyms'], 'expansion': {row['acronyms']: row['manual_expanded_acronyms']}}) for row in data_test\n",
    "    ]\n",
    "\n",
    "    return trainset, devset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6D0LTXkCa1O4"
   },
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df[['text','manual_expanded_acronyms', 'detected_acronyms_LLaMA','expanded_LLaMA']]\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnrXaXP6bGw_"
   },
   "outputs": [],
   "source": [
    "def create_examples(df):\n",
    "    examples = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Asegurar que ambos campos, acrónimos y expansiones, contienen datos\n",
    "        if pd.notna(row['detected_acronyms_LLaMA']) and pd.notna(row['expanded_LLaMA']):\n",
    "            acronyms_list = [acr.strip() for acr in row['detected_acronyms_LLaMA'].split(',')]\n",
    "            expansions_list = [exp.strip() for exp in row['expanded_LLaMA'].split(',')]\n",
    "\n",
    "            # Verificar que ambos listados tengan el mismo número de elementos\n",
    "            if len(acronyms_list) != len(expansions_list):\n",
    "                print(f\"Error en la fila {index}: Número desigual de acrónimos y expansiones.\")\n",
    "                print(f\"Fila problemática: {row.to_dict()}\")\n",
    "                continue\n",
    "\n",
    "            # Crear un ejemplo por cada acrónimo y su correspondiente expansión\n",
    "            for acr, exp in zip(acronyms_list, expansions_list):\n",
    "                examples.append(dspy.Example({\n",
    "                    'texto': row['text'],\n",
    "                    'acronimo': acr,\n",
    "                    'expansion_correcta': exp\n",
    "                }).with_inputs('texto', 'acronimo'))\n",
    "        else:\n",
    "            print(f\"Datos faltantes en la fila {index}.\")\n",
    "            print(f\"Fila problemática: {row.to_dict()}\")\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCsd02HSbHHn"
   },
   "outputs": [],
   "source": [
    "train_examples = create_examples(train_df)\n",
    "test_examples = create_examples(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AefTljbmbHKG"
   },
   "outputs": [],
   "source": [
    "train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBlKtMM-bJ72"
   },
   "outputs": [],
   "source": [
    "test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp1MHUG0bJ-d"
   },
   "outputs": [],
   "source": [
    "print(len(test_examples))\n",
    "print(len(train_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTkJ5GiCbKA8"
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo de SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwcOgHzwbKEE"
   },
   "outputs": [],
   "source": [
    "def validate_expansion(example, pred, trace = None):\n",
    "\n",
    "    prediction_embedding = model.encode(pred.expansion)\n",
    "    reference_embedding = model.encode(example.expansion_correcta)\n",
    "\n",
    "    print(\"La pred embedding es:\", prediction_embedding)\n",
    "    print(\"La ref embedding es:\", reference_embedding)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    similarity = cosine_similarity([prediction_embedding], [reference_embedding])[0][0]\n",
    "\n",
    "    # Evaluar si la similitud está por encima de un umbral-> [-1,1]\n",
    "    if similarity > 0.9:\n",
    "        # Considerando que si está por encima de 0.9 es un acierto\n",
    "        print(similarity)\n",
    "        return True\n",
    "    else:\n",
    "        print(similarity)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vTd4ypSbQ_H"
   },
   "outputs": [],
   "source": [
    "# Testing validate_expansion metric\n",
    "example = type('Example', (object,), {'expansion_correcta': \"El PDF, formato de documento portátil, se ha convertido en un estándar para la distribución de documentos en línea. Permite a los usuarios compartir información de manera segura y profesional, preservando el formato original independientemente del software o dispositivo utilizado para su visualización.\"})\n",
    "pred = type('Prediction', (object,), {'expansion': \"En el campo de la ingeniería, es crucial para evaluar la fiabilidad de estructuras y materiales. Ayuda a los ingenieros a modelar y prever el comportamiento de sistemas complejos mediante el análisis de la distribución de probabilidades. Desde la planificación de proyectos hasta la gestión de riesgos, la PDF proporciona herramientas poderosas para optimizar el diseño y la operación de infraestructuras críticas.\"})\n",
    "is_correct = validate_expansion(example, pred)\n",
    "print(\"¿Es correcta la expansión?:\", is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDSuZ8jBbQ7a"
   },
   "outputs": [],
   "source": [
    "teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "    metric=validate_expansion,\n",
    "    max_bootstrapped_demos=4,\n",
    "    max_labeled_demos=16,\n",
    "    num_candidate_programs=16,\n",
    "    max_rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVj0Mt_6bQ3f"
   },
   "outputs": [],
   "source": [
    "# Usar la clase\n",
    "excel_path = '/export/usuarios_ml4ds/cggamella/RAG_tool/acronyms_paper.xlsx'\n",
    "# Crear conjuntos de entrenamiento y validación\n",
    "#trainset, devset = create_dtset_expanded_acronyms(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ9hwGJibXaN"
   },
   "outputs": [],
   "source": [
    "trainset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNYJ4lXabXVh"
   },
   "outputs": [],
   "source": [
    "devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax4nFMiQbXR_"
   },
   "outputs": [],
   "source": [
    "compiled_model = teleprompter.compile(\n",
    "    acronym_expander,\n",
    "    trainset=train_examples,\n",
    "    valset=test_examples\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
