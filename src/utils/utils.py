import pathlib
import logging
import pandas as pd
import re
import nltk
import yaml
import logging
from nltk.tokenize import sent_tokenize
from src.acronyms_dspy.acronym_detector import AcronymDetectorModule
from src.acronyms_dspy.acronym_expander import AcronymExpanderModule
from src.utils.vector_store_utils import Chunker
'''
def process_dataframe(
    path,
    config,
    chunker=None, 
    acronym_detector=None, 
    context_window=3000, 
    max_windows=100, 
    window_overlap=0.1, 
):
    """
    Processes a DataFrame of text to detect and filter acronyms.
    Parameters:
    - path: str or Path, path to the Excel file containing the data.
    - config: dict, configuration loaded from the YAML file.
    - chunker: instance of Chunker, if not provided, a new one is created with the specified parameters.
    - acronym_detector: instance of AcronymDetectorModule, if not provided, a new one is created.
    - context_window: int, size of the context window for the chunker.
    - max_windows: int, maximum number of windows the chunker can generate.
    - window_overlap: float, percentage of overlap between windows generated by the chunker.

    Returns:
    - df: Processed DataFrame with detected acronyms.
    """
    # Obtain the column name from the configuration file
    column_name = config.get('data_column_name', 'text')

    # Load the DataFrame based on the file extension
    if path.endswith('.xlsx'):
        df = pd.read_excel(path).copy()
    elif path.endswith('.parquet'):
        df = pd.read_parquet(path).copy()
    else:
        raise ValueError("Unsupported file format. Please provide a .xlsx or .parquet file.")

    # Initialize acronym detector and chunker if not provided
    if acronym_detector is None:
        acronym_detector = AcronymDetectorModule()
    
    if chunker is None:
        chunker = Chunker(context_window=context_window, max_windows=max_windows, window_overlap=window_overlap)
    
    # Add a column to store the detected acronyms
    df['Acronyms Detected(LLM)'] = ''

    # Iterate over each row in the DataFrame
    for identifier, row in df.iterrows():
        text = row[column_name]
        print(f"PROCESSING ROW WITH TEXT: {text}")
        if not text:
            print(f"!!Be careful your data haven't got a column with that name. Check YAML file.")
            return

        # Detect acronyms in each chunk of the text
        for id_chunk, chunk in chunker(text):  
            # Detect acronyms in the current chunk
            prediction = acronym_detector.forward(chunk)
            acronyms = clean_acronyms(prediction.ACRONYMS)
            acronyms_list = acronyms.lower().split(',')
            print(f"DETECTED ACR IN CHUNK: {acronyms_list}")

            # Filter detected acronyms
            detected_acronyms = [acronym.strip() for acronym in acronyms_list]
            detected_acronyms = set(detected_acronyms)
            
            print("Filtered detected acronyms (1):", detected_acronyms)
            if not detected_acronyms:
                print(f"No acronyms detected in row {identifier}, continue the loop.")
                continue

            # Remove acronyms with more than 10 characters, more than 1 word, or more than 3 digits
            detected_acronyms = filter_items_and_acronyms(detected_acronyms)
            print("Filtered detected acronyms after filter_items_and_acronyms:", detected_acronyms)
            # Acronyms that contains SL and equivalent forms in the text are removed
            detected_acronyms = filter_companies(detected_acronyms)
            print("Filtered detected acronyms after filter_companies:", detected_acronyms)
            # Acronyms that are not present in the text are removed
            print("Text before disambiguation_in_text:", text)
            detected_acronyms = filter_acronyms_in_text(text, detected_acronyms)
            print("Filtered detected acronyms after filter_acronyms_in_text:", detected_acronyms)
            
            if not detected_acronyms:
                print(f"No acronyms AFTER FILTERING in row {identifier}, continue the loop.")
                continue

            # Update the DataFrame with the detected acronyms
            df.at[identifier, 'Acronyms Detected(LLM)'] = ', '.join(detected_acronyms)

    return df[[column_name, 'Acronyms Detected(LLM)']]
'''
def process_dataframe(
    path,
    config,
    action,
    chunker=None, 
    acronym_detector=None, 
    acronym_expander=None,
    context_window=3000, 
    max_windows=100, 
    window_overlap=0.1,
    logger=None,
):
    """
    Processes a DataFrame of text to detect and expand acronyms based on the action specified.
    
    Parameters:
    - path: str or Path, path to the Excel file containing the data.
    - config: dict, configuration loaded from the YAML file.
    - action: str, action to perform: "detect", "expand", or "both".
    - chunker: instance of Chunker, if not provided, a new one is created with the specified parameters.
    - acronym_detector: instance of AcronymDetectorModule, if not provided, a new one is created.
    - acronym_expander: instance of AcronymExpanderModule, used to expand detected acronyms.
    - context_window: int, size of the context window for the chunker.
    - max_windows: int, maximum number of windows the chunker can generate.
    - window_overlap: float, percentage of overlap between windows generated by the chunker.

    Returns:
    - df: Processed DataFrame with detected and/or expanded acronyms.
    """
    # Obtain the column name from the configuration file
    column_name = config.get('data_column_name', 'text')

    # Load the DataFrame based on the file extension
    if path.endswith('.xlsx'):
        df = pd.read_excel(path).copy()
    elif path.endswith('.parquet'):
        df = pd.read_parquet(path).copy()
    else:
        raise ValueError("Unsupported file format. Please provide a .xlsx or .parquet file.")

    if chunker is None:
        chunker = Chunker(context_window=context_window, max_windows=max_windows, window_overlap=window_overlap)
        
    # Add columns to store the detected acronyms and their expansions
    if action in ["detect", "both"]:
        df['Acronyms Detected(LLM)'] = ''
    if action in ["expand", "both"]:
        df['Expansions'] = ''

    # Iterate over each row in the DataFrame
    for identifier, row in df.iterrows():
        text = row[column_name]
        print(f"PROCESSING ROW WITH TEXT: {text}")
        if not text:
            logger.error("La columna especificada no contiene texto. Verifica el archivo YAML.")
            continue

        detected_acronyms = set()  # Initialize detected_acronyms as an empty set
        all_expansions = []

        # Perform detection if action is "detect" or "both"
        if action in ["detect", "both"] and acronym_detector:
            for id_chunk, chunk in chunker(text):  
                prediction = acronym_detector.forward(chunk)
                acronyms = clean_acronyms(prediction.ACRONYMS)
                acronyms_list = acronyms.lower().split(',')
                print(f"DETECTED ACR IN CHUNK: {acronyms_list}")

                # Filter detected acronyms
                detected_acronyms.update(acronym.strip() for acronym in acronyms_list)
                
                # Apply various filters to the detected acronyms
                detected_acronyms = filter_items_and_acronyms(detected_acronyms)
                detected_acronyms = filter_companies(detected_acronyms)
                detected_acronyms = filter_acronyms_in_text(text, detected_acronyms)

                if not detected_acronyms:
                    print(f"No acronyms AFTER FILTERING in row {identifier}, continue the loop.")
                    continue

                # Update the DataFrame with the detected acronyms
                df.at[identifier, 'Acronyms Detected(LLM)'] = ', '.join(detected_acronyms)

        # Perform expansion if action is "expand" or "both"
        if action in ["expand", "both"] and acronym_expander:
            # Ensure that the detected acronyms are present for expansion when "both" is selected
            if action == "both" and not detected_acronyms:
                acronyms_detected = row.get('Acronyms Detected(LLM)', '')
                detected_acronyms = set(acronyms_detected.split(',')) if acronyms_detected else set()
                
            if not detected_acronyms:
                logger.error(f"No se detectaron acrónimos en la fila {identifier}. No se puede aplicar la expansión.")
                continue

            expansions = []  # Initialize expansions list for each row
            acronyms_list = [acronym.strip() for acronym in detected_acronyms]  # Use detected acronyms list

            for acronym in acronyms_list:  # Iterate through each acronym in the detected list
                try:
                    # Expand the acronym using the forward method of AcronymExpanderModule
                    expansion_response = acronym_expander.forward(texto=text, acronimo=acronym)
                    expansion = expansion_response.EXPANSION
                    print(f"EXPANDED ACRONYM {acronym} TO: {expansion}")
                    expansions.append(f"{acronym}: {expansion}")
                except Exception as e:
                    logger.error(f"Error expanding {acronym} in row {identifier}: {e}")

            # Update the DataFrame with the expansions for each row
            df.at[identifier, 'Expansions'] = '; '.join(expansions)

    # Return only the relevant columns based on the action
    if action == "detect":
        return df[[column_name, 'Acronyms Detected(LLM)']]
    elif action == "expand":
        # Ensure that acronyms have been detected before expanding
        if 'Acronyms Detected(LLM)' not in df.columns or df['Acronyms Detected(LLM)'].isnull().all():
            logger.error("No se puede aplicar la expansión porque no se detectaron acrónimos.")
            raise ValueError("La expansión no puede aplicarse sin detección previa de acrónimos.")
        return df[[column_name, 'Expansions']]
    else:  # both
        return df[[column_name, 'Acronyms Detected(LLM)', 'Expansions']]




def filter_acronyms_in_text(text, acronyms):
    
    text_lower = text.lower() 
    # Filter acronyms based on whether they are found within the text
    filtered_acronyms = [acronym for acronym in acronyms if acronym.lower() in text_lower.split()]
    print("Filtered acronyms:", filtered_acronyms)

    # Return the filtered list of acronyms or '/' if none are found
    return filtered_acronyms if filtered_acronyms else '/'

def filter_companies(acronyms):
    """
    Filters out acronyms that contain any variant of 'SL', 'SLU', or 'SA'.
    """
    pattern = re.compile(r'\b(?:S\.?L\.?(?:U\.?)?|S\.?A\.?)\b', re.IGNORECASE)
    filtered_acronyms = [acronym for acronym in acronyms if not pattern.search(acronym)]
    return filtered_acronyms

def filter_items_and_acronyms(items):
    """
    Filters items from a list based on the following criteria:
    - The item must be 10 characters or fewer.
    - The item must contain only one word.
    - The item must have three or fewer digits.
    - The item must be longer than one character.
    """
    filtered_items = [
        item for item in items
        if len(item) <= 10
        and len(item.split()) <= 1
        and sum(c.isdigit() for c in item) <= 3
        and len(item) > 1
    ]
    return filtered_items

def disambiguation_in_text(text, acronym, expansion):
    """
    This function locates all occurrences of the acronym in the text and replaces them with the expansion.
    
    text: The text in which the replacement should be made.
    acronym: The acronym to search for in the text.
    expansion: The expansion that will replace the acronym in the text.
    """
    # Regex pattern to find the acronym
    pattern = re.compile(r'\b' + re.escape(acronym) + r'\b')
    
    # Replace all occurrences of the acronym with the expansion
    result_text = pattern.sub(expansion, text)
    
    return result_text 

def extract_passages(text, acronym):
        """
        Extract the two preceding and two following sentences after the first appearance of the acronym in
        the text.
        """
        sentences = sent_tokenize(text)
        for i, sentence in enumerate(sentences):
            if acronym.lower() in sentence.lower():
                start = max(i - 2, 0)
                end = min(i + 3, len(sentences))
                return ' '.join(sentences[start:end])
        return None

def clean_acronyms(text):
    """
        Remove '(..text..)' inside parenthesis. Useful to clean LLM extra information.
    """
    cleaned_text = re.sub(r'\s*\([^)]*\)', '', text)
    return cleaned_text.strip()

def init_logger(config: dict) -> logging.Logger:
    """
    Initialize a logger based on the provided configuration.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing logger settings.

    Returns
    -------
    logging.Logger
        The initialized logger.
    """
    name = config.get("logger_name", "app-log")
    log_level = getattr(logging, config.get("log_level", "INFO").upper())
    dir_logger = pathlib.Path(config.get("dir_logger", "logs/app.log"))

    logger = logging.getLogger(name)
    logger.setLevel(log_level)
    
    # Create path_logs dir if it does not exist
    dir_logger.parent.mkdir(parents=True, exist_ok=True)

    # Create handlers based on config
    if config.get("file_log", True):
        file_handler = logging.FileHandler(dir_logger)
        file_handler.setLevel(log_level)
        file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(file_format)
        logger.addHandler(file_handler)

    if config.get("console_log", True):
        console_handler = logging.StreamHandler()
        console_handler.setLevel(log_level)
        console_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(console_format)
        logger.addHandler(console_handler)

    return logger