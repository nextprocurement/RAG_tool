import pathlib
import logging
import pandas as pd
import re
import nltk
import yaml
import logging
from time import sleep
from nltk.tokenize import sent_tokenize
from src.acronyms.acronym_detector import AcronymDetectorModule
from src.acronyms.acronym_expander import AcronymExpanderModule
from src.utils.vector_store_utils import Chunker

def process_dataframe(
    path,
    config,
    action,
    chunker=None, 
    acronym_detector=None, 
    acronym_expander=None,
    context_window=3000, 
    max_windows=100, 
    window_overlap=0.1,
    logger=None,
):
    """
    Processes a DataFrame of text to detect and expand acronyms based on the action specified.
    
    Parameters:
    - path: str or Path, path to the Excel file containing the data.
    - config: dict, configuration loaded from the YAML file.
    - action: str, action to perform: "detect", "expand", or "both".
    - chunker: instance of Chunker, if not provided, a new one is created with the specified parameters.
    - acronym_detector: instance of AcronymDetectorModule, if not provided, a new one is created.
    - acronym_expander: instance of AcronymExpanderModule, used to expand detected acronyms.
    - context_window: int, size of the context window for the chunker.
    - max_windows: int, maximum number of windows the chunker can generate.
    - window_overlap: float, percentage of overlap between windows generated by the chunker.

    Returns:
    - df: Processed DataFrame with detected and/or expanded acronyms.
    """
    # Obtain the column name from the configuration file
    column_name = config.get('data_column_name', 'text')

    # Load the DataFrame based on the file extension
    if path.endswith('.xlsx'):
        df = pd.read_excel(path).copy()
    elif path.endswith('.parquet'):
        df = pd.read_parquet(path).copy()
    else:
        raise ValueError("Unsupported file format. Please provide a .xlsx or .parquet file.")

    if chunker is None:
        chunker = Chunker(context_window=context_window, max_windows=max_windows, window_overlap=window_overlap)
        
    # Add columns to store the detected acronyms and their expansions
    if action in ["detect", "both"]:
        df['Acronyms Detected(LLM)'] = ''
    if action in ["expand", "both"]:
        df['Expansions'] = ''

    # Iterate over each row in the DataFrame
    for identifier, row in df.iterrows():
        text = row[column_name]
        print(f"PROCESSING ROW WITH TEXT: {text}")
        if not text:
            logger.error("La columna especificada no contiene texto. Verifica el archivo YAML.")
            continue

        detected_acronyms = set()  # Initialize detected_acronyms as an empty set

        # Perform detection if action is "detect" or "both"
        if action in ["detect", "both"] and acronym_detector:
            for id_chunk, chunk in chunker(text):  
                prediction = acronym_detector.forward(chunk)
                print("ACRONYMS BEFORE FILTER AND CLEAN:", prediction.ACRONYMS)
                sleep(3)
                acronyms = clean_acronyms(prediction.ACRONYMS)
                acronyms_list = acronyms.lower().split(',')
                print("ACRONYMS BEFORE FILTER:", acronyms_list)
                sleep(3)

                # Filter detected acronyms
                detected_acronyms.update(acronym.strip() for acronym in acronyms_list)
                
                # Apply filters to the detected acronyms
                detected_acronyms = filter_split_characters(detected_acronyms)
                detected_acronyms = filter_items_and_acronyms(detected_acronyms)
                detected_acronyms = filter_companies(detected_acronyms)
                detected_acronyms = filter_acronyms_in_text(text, detected_acronyms)

                if not detected_acronyms:
                    print(f"No acronyms AFTER FILTERING in row {identifier}, continue the loop.")
                    df.at[identifier, 'Acronyms Detected(LLM)'] = '/'
                    continue
                
                print("ACRONYMS AFTER FILTER: ", detected_acronyms)
                # Update the DataFrame with the detected acronyms
                df.at[identifier, 'Acronyms Detected(LLM)'] = ', '.join(detected_acronyms)

        # Perform expansion if action is "expand" or "both"
        if action in ["expand", "both"] and acronym_expander:
            if action == "expand":
                if 'Acronyms Detected(LLM)' not in df.columns:
                    logger.error("Column 'Acronyms Detected(LLM)' does not exists in DataFrame. Cannot apply expansion before detection!.")
                    continue
            
            # Access the updated value directly from the DataFrame using .loc
            acronyms_detected = df.loc[identifier, 'Acronyms Detected(LLM)']
            print(f"ACRONYMS DETECTED IN ROW {identifier}: {acronyms_detected}")
            sleep(10)

            # Skip the row if acronyms are not detected or contain '/' or are empty
            if acronyms_detected in ['/', '']:
                logger.error(f"No acronyms detected in the row {identifier}. Expansion cannot be applied.")
                continue

            detected_acronyms = set(acronym.strip() for acronym in acronyms_detected.split(','))
            expansions = []
            
            # Iterate through each acronym in the detected list
            for acronym in detected_acronyms:
                try:
                    # Expand the acronym using the forward method of AcronymExpanderModule
                    expansion_response = acronym_expander.forward(texto=text, acronimo=acronym)
                    expansion = expansion_response.EXPANSION
                    print(f"EXPANSION FOR ACRONYM {acronym}: {expansion}")
                    sleep(10)
                    expansions.append(expansion)
                      
                except Exception as e:
                    logger.error(f"Error expanding {acronym} in row {identifier}: {e}")

            # Update the DataFrame with the expansions for each row
            df.at[identifier, 'Expansions'] = ', '.join(expansions)

    # Return only the relevant columns based on the action
    if action == "detect":
        return df[[column_name, 'Acronyms Detected(LLM)']]
    else:
        # Ensure that acronyms have been detected before expanding
        if 'Acronyms Detected(LLM)' not in df.columns or df['Acronyms Detected(LLM)'].isnull().all():
            logger.error("No se puede aplicar la expansión porque no se detectaron acrónimos.")
            raise ValueError("La expansión no puede aplicarse sin detección previa de acrónimos.")
        return df[[column_name,'Acronyms Detected(LLM)','Expansions']]

def filter_split_characters(acronyms):
    """
    Processes a list of acronyms. If an acronym contains parts separated by spaces
    and one of the parts is completely numeric, it retains only the alphabetic parts.
    """
    filtered_acronyms = []
    for acronym in acronyms:
        parts = acronym.split()
        # Check if there is at least one numeric part
        if any(part.isdigit() for part in parts):
            # Retain only alphabetic parts
            filtered_acronyms.append(' '.join(part for part in parts if not part.isdigit()))
        else:
            filtered_acronyms.append(acronym)
              
    return filtered_acronyms

def filter_acronyms_in_text(text, acronyms):
    '''
    Filter acronyms based on their presence in the text. Taking into account acronyms enclosed in parentheses.
    '''
    text_lower = text.lower()
    # Find all acronyms enclosed in parentheses
    acronyms_in_parentheses = re.findall(r'\(([^)]+)\)', text)
    # Flatten the list of acronyms found in parentheses and convert to lowercase
    acronyms_in_parentheses = [acronym.lower() for group in acronyms_in_parentheses for acronym in group.split()]
    
    # Filter acronyms based on their presence in the text, excluding those in parentheses
    filtered_acronyms = [
        acronym for acronym in acronyms
        if acronym.lower() in text_lower.split() or acronym.lower() in acronyms_in_parentheses
    ]
    # Return the filtered list of acronyms or '/' if none are found
    return filtered_acronyms if filtered_acronyms else '/'

def filter_companies(acronyms):
    """
    Filters out acronyms that contain any variant of 'SL', 'SLU', or 'SA'.
    """
    pattern = re.compile(r'\b(?:S\.?L\.?(?:U\.?)?|S\.?A\.?)\b', re.IGNORECASE)
    filtered_acronyms = [acronym for acronym in acronyms if not pattern.search(acronym)]
    return filtered_acronyms

def filter_items_and_acronyms(items):
    """
    Filters items from a list based on the following criteria:
    - The item must be 14 characters or fewer.
    - The item must contain only one word.
    - The item must have three or fewer digits.
    - The item must be longer than one character.
    - The item must not be a number.
    """
    filtered_items = [
        item for item in items
        if len(item) <= 14
        and len(item.split()) <= 2
        and sum(c.isdigit() for c in item) <= 3
        and len(item) > 1
        and not item.isdigit()
    ]
    return filtered_items

def disambiguation_in_text(text, acronym, expansion):
    """
    This function locates all occurrences of the acronym in the text and replaces them with the expansion.
    
    text: The text in which the replacement should be made.
    acronym: The acronym to search for in the text.
    expansion: The expansion that will replace the acronym in the text.
    """
    # Regex pattern to find the acronym
    pattern = re.compile(r'\b' + re.escape(acronym) + r'\b')
    
    # Replace all occurrences of the acronym with the expansion
    result_text = pattern.sub(expansion, text)
    
    return result_text 

def extract_passages(text, acronym):
        """
        Extract the two preceding and two following sentences after the first appearance of the acronym in
        the text.
        """
        sentences = sent_tokenize(text)
        for i, sentence in enumerate(sentences):
            if acronym.lower() in sentence.lower():
                start = max(i - 2, 0)
                end = min(i + 3, len(sentences))
                return ' '.join(sentences[start:end])
        return None

def clean_acronyms(text):
    """
        Remove '(..text..)' inside parenthesis. Useful to clean LLM extra information.
    """
    cleaned_text = re.sub(r'\s*\([^)]*\)', '', text)
    return cleaned_text.strip()

def init_logger(config: dict) -> logging.Logger:
    """
    Initialize a logger based on the provided configuration.

    Parameters
    ----------
    config : dict
        Configuration dictionary containing logger settings.

    Returns
    -------
    logging.Logger
        The initialized logger.
    """
    name = config.get("logger_name", "app-log")
    log_level = getattr(logging, config.get("log_level", "INFO").upper())
    dir_logger = pathlib.Path(config.get("dir_logger", "logs/app.log"))

    logger = logging.getLogger(name)
    logger.setLevel(log_level)
    
    # Create path_logs dir if it does not exist
    dir_logger.parent.mkdir(parents=True, exist_ok=True)

    # Create handlers based on config
    if config.get("file_log", True):
        file_handler = logging.FileHandler(dir_logger)
        file_handler.setLevel(log_level)
        file_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(file_format)
        logger.addHandler(file_handler)

    if config.get("console_log", True):
        console_handler = logging.StreamHandler()
        console_handler.setLevel(log_level)
        console_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(console_format)
        logger.addHandler(console_handler)

    return logger